<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>golang 内存管理</title>
      <link href="/2021/08/27/golang-nei-cun-guan-li/"/>
      <url>/2021/08/27/golang-nei-cun-guan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>要搞明白 Go 语言的内存管理，就必须先理解操作系统以及机器硬件是如何管理内存的。因为 Go 语言的内部机制是建立在这个基础之上的，它的设计，本质上就是尽可能的会发挥操作系统层面的优势，而避开导致低效情况。</p><h2 id="操作系统内存管理"><a href="#操作系统内存管理" class="headerlink" title="操作系统内存管理"></a>操作系统内存管理</h2><p>其实现在计算机内存管理的方式都是一步步演变来的，最开始是非常简单的，后来为了满足各种需求而增加了各种各样的机制，越来越复杂。这里我们只介绍和开发者息息相关的几个机制。</p><h3 id="最原始的方式"><a href="#最原始的方式" class="headerlink" title="最原始的方式"></a>最原始的方式</h3><p>我们可以把内存看成一个数组，每个数组元素的大小是 <code>1B</code>，也就是 8 位(bit)。CPU 通过内存地址来获取内存中的数据，内存地址可以看做成数组的游标（index）。</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc1.webp"></p><p>CPU 在执行指令的时候，就是通过内存地址，将物理内存上的数据载入到寄存器，然后执行机器指令。但随着发展，出现了多任务的需求，也就是希望多个任务能同时在系统上运行。这就出现了一些问题：</p><ol><li><strong>内存访问冲突：</strong>程序很容易出现 bug，就是 2 或更多的程序使用了同一块内存空间，导致数据读写错乱，程序崩溃。更有一些黑客利用这个缺陷来制作病毒。</li><li><strong>内存不够用：</strong>因为每个程序都需要自己单独使用的一块内存，内存的大小就成了任务数量的瓶颈。</li><li><strong>程序开发成本高：</strong>你的程序要使用多少内存，内存地址是多少，这些都不能搞错，对于人来说，开发正确的程序很费脑子。</li></ol><p>举个例子，假设有一个程序，当代码运行到某处时，需要使用 <code>100M</code> 内存，其他时候 <code>1M</code> 内存就够；为了避免和其他程序冲突，程序初始化时，就必须申请独立 <code>100M</code> 内存以保证正常运行，这就是一种很大的浪费，因为这 <code>100M</code> 它大多数时候用不上，其他程序还不能用。</p><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>虚拟内存的出现，很好的为了解决上述的一些列问题。用户程序只能使用虚拟的内存地址来获取数据，系统会将这个虚拟地址翻译成实际的物理地址。</p><p>所有程序统一使用一套连续虚拟地址，比如 <code>0x0000 ~ 0xffff</code>。从程序的角度来看，它觉得自己独享了一整块内存。不用考虑访问冲突的问题。系统会将虚拟地址翻译成物理地址，从内存上加载数据。</p><p>对于内存不够用的问题，虚拟内存本质上是将磁盘当成最终存储，而主存作为了一个 cache。程序可以从虚拟内存上申请很大的空间使用，比如 <code>1G</code>；但操作系统不会真的在物理内存上开辟 <code>1G</code> 的空间，它只是开辟了很小一块，比如 <code>1M</code> 给程序使用。<br> 这样程序在访问内存时，操作系统看访问的地址是否能转换成物理内存地址。能则正常访问，不能则再开辟。这使得内存得到了更高效的利用。</p><p>如下图所示，每个进程所使用的虚拟地址空间都是一样的，但他们的虚拟地址会被映射到主存上的不同区域，甚至映射到磁盘上（当内存不够用时）。</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc2.webp"></p><p>虚拟地址</p><p>其实本质上很简单，就是操作系统将程序常用的数据放到内存里加速访问，不常用的数据放在磁盘上。这一切对用户程序来说完全是透明的，用户程序可以假装所有数据都在内存里，然后通过虚拟内存地址去访问数据。在这背后，操作系统会自动将数据在主存和磁盘之间进行交换。</p><h4 id="虚拟地址翻译"><a href="#虚拟地址翻译" class="headerlink" title="虚拟地址翻译"></a>虚拟地址翻译</h4><p>虚拟内存的实现方式，大多数都是通过<strong>页表</strong>来实现的。操作系统虚拟内存空间分成一页一页的来管理，每页的大小为 <code>4K</code>（当然这是可以配置的，不同操作系统不一样）。磁盘和主内存之间的置换也是以<strong>页</strong>为单位来操作的。<code>4K</code> 算是通过实践折中出来的通用值，太小了会出现频繁的置换，太大了又浪费内存。</p><p><code>虚拟地址 -&gt; 物理地址</code> 的映射关系由<strong>页表（Page Table）</strong>记录，它其实就是一个数组，数组中每个元素叫做<strong>页表条目（Page Table Entry，简称 PTE）</strong>，PTE 由一个有效位和 n 位地址字段构成，有效位标识这个虚拟地址是否分配了物理内存。</p><p>页表被操作系统放在物理内存的指定位置，CPU  上有个 Memory Management Unit（MMU） 单元，CPU 把虚拟地址给 MMU，MMU 去物理内存中查询页表，得到实际的物理地址。当然 MMU 不会每次都去查的，它自己也有一份缓存叫Translation Lookaside Buffer (TLB)，是为了加速地址翻译。</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc3.webp"></p><p>虚拟地址翻译</p><blockquote><p>你慢慢会发现整个计算机体系里面，缓存是无处不在的，整个计算机体系就是建立在一级级的缓存之上的，无论软硬件。</p></blockquote><p>让我们来看一下 CPU 内存访问的完整过程：</p><ol><li>CPU 使用虚拟地址访问数据，比如执行了 MOV 指令加载数据到寄存器，把地址传递给 MMU。</li><li>MMU 生成 PTE 地址，并从主存（或自己的 Cache）中得到它。</li><li>如果 MMU 根据 PTE 得到真实的物理地址，正常读取数据。流程到此结束。</li><li>如果 PTE 信息表示没有关联的物理地址，MMU 则触发一个缺页异常。</li><li>操作系统捕获到这个异常，开始执行异常处理程序。在物理内存上创建一页内存，并更新页表。</li><li>缺页处理程序在物理内存中确定一个<strong>牺牲页</strong>，如果这个牺牲页上有数据，则把数据保存到磁盘上。</li><li>缺页处理程序更新 PTE。</li><li>缺页处理程序结束，再回去执行上一条指令（导致缺页异常的那个指令，也就是 MOV 指令）。这次肯定命中了。</li></ol><h4 id="内存命中率"><a href="#内存命中率" class="headerlink" title="内存命中率"></a>内存命中率</h4><p>你可能已经发现，上述的访问步骤中，从第 4 步开始都是些很繁琐的操作，频繁的执行对性能影响很大。毕竟访问磁盘是非常慢的，它会引发程序性能的急剧下降。如果内存访问到第 3 步成功结束了，我们就说<strong>页命中</strong>了；反之就是<strong>未命中</strong>，或者说<strong>缺页</strong>，表示它开始执行第 4 步了。</p><p>假设在 n 次内存访问中，出现命中的次数是 m，那么 <code>m / n * 100%</code> 就表示命中率，这是衡量内存管理程序好坏的一个很重要的指标。</p><p>如果物理内存不足了，数据会在主存和磁盘之间频繁交换，命中率很低，性能出现急剧下降，我们称这种现象叫<strong>内存颠簸</strong>。这时你会发现系统的 swap 空间利用率开始增高， CPU 利用率中 <code>iowait</code> 占比开始增高。</p><p>大多数情况下，只要物理内存够用，页命中率不会非常低，不会出现内存颠簸的情况。因为大多数程序都有一个特点，就是<strong>局部性</strong>。</p><p><strong>局部性就是说被引用过一次的存储器位置，很可能在后续再被引用多次；而且在该位置附近的其他位置，也很可能会在后续一段时间内被引用。</strong></p><p>前面说过计算机到处使用一级级的缓存来提升性能，归根结底就是利用了<strong>局部性</strong>的特征，如果没有这个特性，一级级的缓存不会有那么大的作用。所以一个局部性很好的程序运行速度会更快。</p><hr><h2 id="golang内存管理"><a href="#golang内存管理" class="headerlink" title="golang内存管理"></a>golang内存管理</h2><p>了解操作系统对内存的管理机制后，现在可以去看下 Go 语言是如何利用底层的这些特性来优化内存的。Go 的内存管理基本上参考 <code>tcmalloc</code> 来实现的，只是细节上根据自身的需要做了一些小的优化调整。</p><p>Go 的内存是自动管理的，我们可以随意定义变量直接使用，不需要考虑变量背后的内存申请和释放的问题。本文意在搞清楚 Go 在方面帮我们做了什么，使我们不用关心那些复杂内存的问题，还依旧能写出较为高效的程序。</p><h2 id="池"><a href="#池" class="headerlink" title="池"></a>池</h2><p>程序动态申请内存空间，是要使用系统调用的，比如 Linux 系统上是调用 <code>mmap</code> 方法实现的。但对于大型系统服务来说，直接调用 <code>mmap</code> 申请内存，会有一定的代价。比如：</p><ol><li>系统调用会导致程序进入内核态，内核分配完内存后（也就是上篇所讲的，对虚拟地址和物理地址进行映射等操作），再返回到用户态。</li><li>频繁申请很小的内存空间，容易出现大量内存碎片，增大操作系统整理碎片的压力。</li><li>为了保证内存访问具有良好的局部性，开发者需要投入大量的精力去做优化，这是一个很重的负担。</li></ol><p>如何解决上面的问题呢？有经验的人，可能很快就想到解决方案，那就是我们常说的<strong>对象池</strong>（也可以说是缓存）。</p><p>假设系统需要频繁动态申请内存来存放一个数据结构，比如 <code>[10]int</code>。那么我们完全可以在程序启动之初，一次性申请几百甚至上千个 <code>[10]int</code>。这样完美的解决了上面遇到的问题：</p><ol><li>不需要频繁申请内存了，而是从对象池里拿，程序不会频繁进入内核态</li><li>因为一次性申请一个连续的大空间，对象池会被重复利用，不会出现碎片。</li><li>程序频繁访问的就是对象池背后的同一块内存空间，局部性良好。</li></ol><p>这样做会造成一定的内存浪费，我们可以定时检测对象池的大小，保证可用对象的数量在一个合理的范围，少了就提前申请，多了就自动释放。</p><p>如果某种资源的申请和回收是昂贵的，我们都可以通过建立<strong>资源池</strong>的方式来解决，其他比如<strong>连接池</strong>，<strong>内存池</strong>等等，都是一个思路。</p><h2 id="Golang-内存管理"><a href="#Golang-内存管理" class="headerlink" title="Golang 内存管理"></a>Golang 内存管理</h2><p>Golang 的内存管理本质上就是一个内存池，只不过内部做了很多的优化。比如自动伸缩内存池大小，合理的切割内存块等等。</p><h3 id="内存池-mheap"><a href="#内存池-mheap" class="headerlink" title="内存池 mheap"></a>内存池 mheap</h3><p>Golang 的程序在启动之初，会一次性从操作系统那里申请一大块内存作为内存池。这块内存空间会放在一个叫 <code>mheap</code> 的 <code>struct</code> 中管理，mheap 负责将这一整块内存切割成不同的区域，并将其中一部分的内存切割成合适的大小，分配给用户使用。</p><p>我们需要先知道几个重要的概念：</p><ul><li><strong><code>page</code></strong>: 内存页，一块 <code>8K</code> 大小的内存空间。Go 与操作系统之间的内存申请和释放，都是以 <code>page</code> 为单位的。</li><li><strong><code>span</code></strong>: 内存块，<strong>一个或多个连续的</strong> <code>page</code> 组成一个 <code>span</code>。如果把 <code>page</code> 比喻成工人，<code>span</code> 可看成是小队，工人被分成若干个队伍，不同的队伍干不同的活。</li><li><strong><code>sizeclass</code></strong>: 空间规格，每个 <code>span</code> 都带有一个 <code>sizeclass</code>，标记着该 <code>span</code> 中的 <code>page</code> 应该如何使用。使用上面的比喻，就是 <code>sizeclass</code> 标志着 <code>span</code> 是一个什么样的队伍。</li><li><strong><code>object</code></strong>: 对象，用来存储一个变量数据内存空间，一个 <code>span</code> 在初始化时，会被切割成一堆<strong>等大</strong>的 <code>object</code>。假设 <code>object</code> 的大小是 <code>16B</code>，<code>span</code> 大小是 <code>8K</code>，那么就会把 <code>span</code> 中的 <code>page</code> 就会被初始化 <code>8K / 16B = 512</code> 个 <code>object</code>。所谓内存分配，就是分配一个 <code>object</code> 出去。</li></ul><p>示意图：</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc4.webp"></p><p>上图中，不同颜色代表不同的 <code>span</code>，不同 <code>span</code> 的 <code>sizeclass</code> 不同，表示里面的 <code>page</code> 将会按照不同的规格切割成一个个等大的 <code>object</code> 用作分配。</p><p>使用 Go1.11.5 版本测试了下初始堆内存应该是 <code>64M</code> 左右，低版本会少点。</p><p>测试代码：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token string">"runtime"</span><span class="token keyword">var</span> stat runtime<span class="token punctuation">.</span>MemStats<span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    runtime<span class="token punctuation">.</span><span class="token function">ReadMemStats</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>stat<span class="token punctuation">)</span>    <span class="token function">println</span><span class="token punctuation">(</span>stat<span class="token punctuation">.</span>HeapSys<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>内部的整体内存布局如下图所示：</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc5.webp"></p><ul><li><code>mheap.spans</code>：用来存储 <code>page</code> 和 <code>span</code> 信息，比如一个 span 的起始地址是多少，有几个 page，已使用了多大等等。</li><li><code>mheap.bitmap</code> 存储着各个 <code>span</code> 中对象的标记信息，比如对象是否可回收等等。</li><li><code>mheap.arena_start</code>: 将要分配给应用程序使用的空间。</li></ul><p>再说明下，图中的空间大小，是 Go 向操作系统申请的虚拟内存地址空间，操作系统会将该段地址空间预留出来不做它用；而不是真的创建出这么大的虚拟内存，在页表中创建出这么大的映射关系。</p><h3 id="mcentral"><a href="#mcentral" class="headerlink" title="mcentral"></a>mcentral</h3><p><strong>用途相同</strong>的 <code>span</code> 会以链表的形式组织在一起。 这里的用途用 <code>sizeclass</code> 来表示，就是指该 <code>span</code> 用来存储哪种大小的对象。比如当分配一块大小为 <code>n</code> 的内存时，系统计算 <code>n</code> 应该使用哪种 <code>sizeclass</code>，然后根据 <code>sizeclass</code> 的值去找到一个可用的 <code>span</code> 来用作分配。其中 <code>sizeclass</code> 一共有 67 种（Go1.5 版本，后续版本可能会不会改变不好说），如图所示：</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc6.webp"></p><p>找到合适的 <code>span</code> 后，会从中取一个 <code>object</code> 返回给上层使用。这些 <code>span</code> 被放在一个叫做 mcentral 的结构中管理。</p><p>mheap 将从 OS 那里申请过来的内存初始化成一个大 <code>span</code>(sizeclass=0)。然后根据需要从这个大 <code>span</code> 中切出小 <code>span</code>，放在 mcentral 中来管理。大 <code>span</code> 由 <code>mheap.freelarge</code> 和 <code>mheap.busylarge</code> 等管理。如果 mcentral 中的 <code>span</code> 不够用了，会从 <code>mheap.freelarge</code> 上再切一块，如果 <code>mheap.freelarge</code> 空间不够，会再次从 OS 那里申请内存重复上述步骤。下面是 mheap 和 mcentral 的数据结构：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> mheap <span class="token keyword">struct</span> <span class="token punctuation">{</span>    <span class="token comment">// other fields</span>    lock      mutex    free      <span class="token punctuation">[</span>_MaxMHeapList<span class="token punctuation">]</span>mspan <span class="token comment">// free lists of given length， 1M 以下</span>    freelarge mspan                <span class="token comment">// free lists length &gt;= _MaxMHeapList, &gt;= 1M</span>    busy      <span class="token punctuation">[</span>_MaxMHeapList<span class="token punctuation">]</span>mspan <span class="token comment">// busy lists of large objects of given length</span>    busylarge mspan                <span class="token comment">// busy lists of large objects length &gt;= _MaxMHeapList</span>    central <span class="token punctuation">[</span>_NumSizeClasses<span class="token punctuation">]</span><span class="token keyword">struct</span> <span class="token punctuation">{</span> <span class="token comment">// _NumSizeClasses = 67</span>        mcentral mcentral        <span class="token comment">// other fields</span>    <span class="token punctuation">}</span>    <span class="token comment">// other fields</span><span class="token punctuation">}</span><span class="token comment">// Central list of free objects of a given size.</span><span class="token keyword">type</span> mcentral <span class="token keyword">struct</span> <span class="token punctuation">{</span>    lock      mutex <span class="token comment">// 分配时需要加锁</span>    sizeclass <span class="token builtin">int32</span> <span class="token comment">// 哪种 sizeclass</span>    nonempty  mspan <span class="token comment">// 还有可用的空间的 span 链表</span>    empty     mspan <span class="token comment">// 没有可用的空间的 span 列表</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种方式可以避免出现外部碎片<em>（文章最后面有外部碎片的介绍）</em>，因为同一个 span 是按照固定大小分配和回收的，不会出现不可利用的一小块内存把内存分割掉。这个设计方式与现代操作系统中的伙伴系统有点类似。</p><h3 id="mcache"><a href="#mcache" class="headerlink" title="mcache"></a>mcache</h3><p>如果你阅读的比较仔细，会发现上面的 mcentral 结构中有一个 lock 字段；因为并发情况下，很有可能多个线程同时从 mcentral 那里申请内存的，必须要用锁来避免冲突。</p><p>但锁是低效的，在高并发的服务中，它会使内存申请成为整个系统的瓶颈；所以在 mcentral 的前面又增加了一层 mcache。</p><p>每一个 mcache 和每一个处理器(P) 是一一对应的，也就是说每一个 P 都有一个 mcache 成员。 Goroutine 申请内存时，首先从其所在的 P 的 mcache 中分配，如果 mcache 没有可用 <code>span</code>，再从 mcentral 中获取，并填充到 mcache 中。</p><p>从 mcache 上分配内存空间是不需要加锁的，因为在同一时间里，一个 P 只有一个线程在其上面运行，不可能出现竞争。没有了锁的限制，大大加速了内存分配。</p><p>所以整体的内存分配模型大致如下图所示：</p><p><img src="https://image.fyxemmmm.cn/blog/images/nc7.webp"></p><h3 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h3><h4 id="zero-size"><a href="#zero-size" class="headerlink" title="zero size"></a>zero size</h4><p>有一些对象所需的内存大小是0，比如 <code>[0]int</code>, <code>struct{}</code>，这种类型的数据根本就不需要内存，所以没必要走上面那么复杂的逻辑。</p><p>系统会直接返回一个固定的内存地址。源码如下：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">mallocgc</span><span class="token punctuation">(</span>size <span class="token builtin">uintptr</span><span class="token punctuation">,</span> typ <span class="token operator">*</span>_type<span class="token punctuation">,</span> flags <span class="token builtin">uint32</span><span class="token punctuation">)</span> unsafe<span class="token punctuation">.</span>Pointer <span class="token punctuation">{</span>    <span class="token comment">// 申请的 0 大小空间的内存</span>    <span class="token keyword">if</span> size <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> unsafe<span class="token punctuation">.</span><span class="token function">Pointer</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>zerobase<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment">//.....</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试代码：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">package</span> main<span class="token keyword">import</span> <span class="token punctuation">(</span>    <span class="token string">"fmt"</span><span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> <span class="token punctuation">(</span>        a <span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span>        b <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token builtin">int</span>        c <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span>        d <span class="token operator">=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"%p\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>a<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"%p\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>b<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"%p\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>c<span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"%p\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token punctuation">(</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"%p\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token punctuation">(</span>d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    fmt<span class="token punctuation">.</span><span class="token function">Printf</span><span class="token punctuation">(</span><span class="token string">"%p\n"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span><span class="token punctuation">(</span>d<span class="token punctuation">[</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment">// 运行结果，6 个变量的内存地址是相同的:</span><span class="token number">0x1180f88</span><span class="token number">0x1180f88</span><span class="token number">0x1180f88</span><span class="token number">0x1180f88</span><span class="token number">0x1180f88</span><span class="token number">0x1180f88</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h4 id="大对象"><a href="#大对象" class="headerlink" title="大对象"></a>大对象</h4><p>如上面所述，最大的 sizeclass 最大只能存放 <code>32K</code> 的对象。如果一次性申请超过 <code>32K</code> 的内存，系统会直接绕过 mcache 和 mcentral，直接从 mheap 上获取，mheap 中有一个 <code>freelarge</code> 字段管理着超大 span。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>内存的释放过程，没什么特别之处。就是分配的返过程，当 mcache 中存在较多空闲 span 时，会归还给 mcentral；而 mcentral 中存在较多空闲 span 时，会归还给 mheap；mheap 再归还给操作系统。这里就不详细介绍了。</p><p>总结一下，这种设计之所以快，主要有以下几个优势：</p><ol><li>内存分配大多时候都是在用户态完成的，不需要频繁进入内核态。</li><li>每个 P 都有独立的 span cache，多个 CPU 不会并发读写同一块内存，进而减少 CPU L1 cache 的 cacheline 出现 dirty 情况，增大 cpu cache 命中率。</li><li>内存碎片的问题，Go 是自己在用户态管理的，在 OS 层面看是没有碎片的，使得操作系统层面对碎片的管理压力也会降低。</li><li>mcache 的存在使得内存分配不需要加锁。</li></ol><hr><h4 id="为什么内存碎片可能影响性能？"><a href="#为什么内存碎片可能影响性能？" class="headerlink" title="为什么内存碎片可能影响性能？"></a>为什么内存碎片可能影响性能？</h4><blockquote><p>Linux 利用 Intel CPU的保护模式，采用页表的方式对内存进行管理。 虚拟线性地址对应着某个页。这之间的对应关系存在于页表之中。 由于几乎每次对虚拟内存中的页面访问都必须先解析页，从而得到物理内存中的对应地址，所以页表操作的性能非常关键。因此，Intel MMU 系统结构中实现了一个TLB（translate lookaside buffer）作为一个将虚拟地址映射到物理地址的硬件缓存，当请求访问一个虚拟地址时，处理器将首先检查TLB是否缓存了该虚拟地址到物理地址的映射，如果命中则直接返回，否则，就需要通过页表搜索需要的物理地址。</p><p>TLB很小，只有64 entries 。当内存碎片化后，一个进程的虚拟线性地址空间对应于数量众多的小片的页，TLB不能容纳这么多的页面表项，这就意味在这个进程的运行期内，MMU在寻址时，TLB总是不能命中，而需要不断的更新。这就大大的降低了执行的效率。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> 内存管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>http2详解 [下]</title>
      <link href="/2021/08/26/http2-xiang-jie-xia/"/>
      <url>/2021/08/26/http2-xiang-jie-xia/</url>
      
        <content type="html"><![CDATA[<h1 id="8-http2的世界"><a href="#8-http2的世界" class="headerlink" title="8. http2的世界"></a>8. http2的世界</h1><p>那么当http2被广泛采用的时候，世界将会成什么样呢？或者说，它会被真正的采用吗？</p><h2 id="8-1-http2会如何影响普通人？"><a href="#8-1-http2会如何影响普通人？" class="headerlink" title="8.1. http2会如何影响普通人？"></a>8.1. http2会如何影响普通人？</h2><p>到目前为止，http2还没被大范围部署使用，我们也无法确定到底会发生什么变化，但至少可以参考SPDY的例子和曾经做过的实验来进行大概的估计。</p><p>http2减少了网络往返传输的数量，并且用多路复用和快速丢弃不需要的流的办法来完全避免了head of line blocking(线头阻塞)的困扰。</p><p>它也支持大量并行流，所以即使网站的数据分发在各处也不是问题。</p><p>合理利用流的优先级，可以让客户端尽可能优先收到更重要的数据。</p><p>所有这些加起来，我认为页面载入时间和站点的响应速度都会更快。简而言之，它们都代表着更好的web体验。</p><p>但到底能变得多快，到底提升有多大呢？我认为目前很难说清楚。毕竟这些技术依然在早期阶段，我们还无法看见客户端和服务器实现这些并真正受益于它所提供的强大功能。</p><h2 id="8-2-http2会如何影响web开发？"><a href="#8-2-http2会如何影响web开发？" class="headerlink" title="8.2. http2会如何影响web开发？"></a>8.2. http2会如何影响web开发？</h2><p>近年来，web开发者、web开发环境为HTTP 1.1存在的一些问题提供了一部分临时的解决方案。其中的一部分我已在上文中简单的介绍了，不妨简单的回忆一下。</p><p>很多工具和开发者可能会默认使用这些方案，但它们其中的一部分也许会损害到http2的性能，或者至少让我们无法真正利用到http2新提供的强大威力。Spriting和内联应该是http2里面最不需要的了。因为http2更倾向于使用更少的连接，所以Sharding甚至会伤害到http2的性能。</p><p>这里的问题在于：对于网站的开发者而言，在短期内开发和部署同一套前端来支持HTTP 1.1和http2的客户端访问并获得最大性能将会是一个挑战。</p><p>考虑到这些问题，我认为彻底发掘http2的潜力还有很长一段路要走。</p><h2 id="8-3-http2的各种实现"><a href="#8-3-http2的各种实现" class="headerlink" title="8.3. http2的各种实现"></a>8.3. http2的各种实现</h2><p>在这样一篇文章中详细说明每个实现细节注定乏味且毫无意义，我将用更通用的术语来解释实际的场景，并在此给大家提供一个http2的<a href="https://github.com/http2/http2-spec/wiki/Implementations">实现列表</a>作为参考。</p><p>在http2的早期就已经有大量的实现。并且在http2标准化工作期间，这个数量还持续增长。截至我写这篇文档的时候，共有40种实现已记录在案，他们中的大多数都实现了最新的草案。</p><h3 id="8-3-1-浏览器"><a href="#8-3-1-浏览器" class="headerlink" title="8.3.1. 浏览器"></a>8.3.1. 浏览器</h3><p>Firefox一直紧跟最新的协议，Twitter也紧追不舍提供了基于http2的服务。2014年4月期间<!--『从2014年4月开始』会不会更符合原意？-->，Google在少数测试服务器上提供http2支持。从同年5月开始，开发版的Chrome支持http2。Microsoft也在他们的产品预发布会上展示了支持http2的下一代浏览器。Safari (iOS 9 以及 Mac OS X El Capitan) 和 Opera也都表态它们将会支持http2。</p><h3 id="8-3-2-服务器"><a href="#8-3-2-服务器" class="headerlink" title="8.3.2 服务器"></a>8.3.2 服务器</h3><p>事实上，已经有不少的服务器实现了http2。</p><p>时下最流行的Nginx自1.9.5(发布于2015年9月22号)版本后提供了对http2的支持并且取缔了原来的SPDY模块(因此SPDY和http2无法同时运行在同一个Nginx服务器实例中)。</p><p>而Apache HTTPD服务器也实现了一个名为<a href="https://httpd.apache.org/docs/2.4/mod/mod_http2.html">mod_http2</a>的http2模块，并与2015年10月9号在2.4.17的版本中发布。</p><p>此外，<a href="https://h2o.examp1e.net/">H2O</a>, <a href="https://trafficserver.apache.org/">Apache Traffic Server</a>, <a href="https://nghttp2.org/">nghttp2</a>, <a href="https://caddyserver.com/">Caddy</a> 以及 <a href="https://www.litespeedtech.com/products/litespeed-web-server/overview">LiteSpeed</a> 也都发布了可以工作于http2下的服务器。</p><h3 id="8-3-3-其他"><a href="#8-3-3-其他" class="headerlink" title="8.3.3 其他"></a>8.3.3 其他</h3><p>curl和libcurl支持未加密的http2并借助某些TLS库支持了TLS版本。</p><p>Wireshark同样支持了http2, 所以用它来分析http2网络数据流着实是再好不过的了。</p><h2 id="8-4-对http2的常见批评"><a href="#8-4-对http2的常见批评" class="headerlink" title="8.4. 对http2的常见批评"></a>8.4. 对http2的常见批评</h2><p>在制定协议的讨论过程中往往存在许多争议，甚至会有不少人认为这样的协议最终会以失败告终。这里我想提一些常见的对协议的批评以及我的解释：</p><h3 id="8-4-1-“这个协议是Google设计制定的”"><a href="#8-4-1-“这个协议是Google设计制定的”" class="headerlink" title="8.4.1. “这个协议是Google设计制定的”"></a>8.4.1. “这个协议是Google设计制定的”</h3><p>江湖上有太多传言暗示着这个世界越来越被Google所控制，但事实显然并非如此。这个协议是IETF制定的，就跟过去30年间很多其他协议一样。但不得不承认，SPDY是Google非常出色的成果。它不仅仅证明了开发一个新协议的可行性，还充分展现了新协议所能带来的好处。</p><p>而Google也公开<a href="https://blog.chromium.org/2015/02/hello-http2-goodbye-spdy.html">声明</a>了他们会在2016年移除Chrome里对SPDY和NPN的支持，并且极力推动服务器迁移至HTTP/2。2016年2月他们<a href="https://blog.chromium.org/2016/02/transitioning-from-spdy-to-http2.html">声明</a>了SPDY和NPN会在Chrome 51被移除.</p><h3 id="8-4-2-“这个协议只在浏览器上有用”"><a href="#8-4-2-“这个协议只在浏览器上有用”" class="headerlink" title="8.4.2. “这个协议只在浏览器上有用”"></a>8.4.2. “这个协议只在浏览器上有用”</h3><p>在一定意义上，这是对的。开发http2的其中一个主要原因就是修复HTTP pipelining。如果在你的应用场景里本来就不需要pipelining，那么确实很有可能http2对你没有太大帮助。虽然这并不是唯一的提升，但显然这是非常重要的一个。</p><p>一旦当某些服务意识到在一个连接上建立多路复用流的强大威力时，我认为会有越来越多的程序采用http2。</p><p>小规模的REST API和采用HTTP 1.x的简单程序可能并不会从迁移到http2中获得多大的收益。但至少，迁移至http2对绝大部分用户来讲几乎是没有坏处的。</p><h3 id="8-4-3-“这个协议只对大型网站有用”"><a href="#8-4-3-“这个协议只对大型网站有用”" class="headerlink" title="8.4.3. “这个协议只对大型网站有用”"></a>8.4.3. “这个协议只对大型网站有用”</h3><p>完全不是这样。因为缺乏内容分发网络，小网站的网络延迟往往较高，而多路复用的能力可以极大的改善在高网络延迟下的体验。大型网站往往已经将内容分发到各处，所以速度其实已经非常快了。</p><h3 id="8-4-4-“TLS让速度变得更慢”"><a href="#8-4-4-“TLS让速度变得更慢”" class="headerlink" title="8.4.4. “TLS让速度变得更慢”"></a>8.4.4. “TLS让速度变得更慢”</h3><p>这个评价在某种程度上是对的。虽然TLS的握手确实增加了额外的开销，但也有越来越多的方案提出来减少TLS往返的时间。使用TLS而不是纯文本带来的开销是显著的，有可观证据表明，和传输同样的流量相比，TLS会消耗更多的CPU和其他资源。具体影响有多大以及怎么影响是一个和具体测量有关的课题。更多的例子可以参看<a href="https://istlsfastyet.com/">istlsfastyet.com</a>。</p><p>Telecom和一些其他网络服务商，例如ATIS开放网络联盟，表示为了为卫星、飞机等提供的快速网络体验，他们需要一些<a href="https://www.atis.org/openweballiance/docs/OWAKickoffSlides051414.pdf">不加密的流量</a>来提供caching，压缩和其他技术。</p><p>由于http2并不强制要求使用TLS，所以我们不应该为此担心。</p><p>如今，很多互联网使用者都希望TLS能被更广泛的使用来保护用户隐私。</p><p>实验也证明了通过使用TLS能比用在80端口实现一个新的基于文本的协议更容易成功。因为当前已经有太多中间商使用该方案，所以凡是基于80端口的协议，都很可能被理所当然的当作HTTP 1.1。</p><p>最后，得益于http2可以在单一连接上提供多路复用的流，正常使用普通浏览器也可以减少TLS握手的次数，所以使用HTTPS仍然会比HTTP 1.1更快。</p><h3 id="8-4-5-“不基于ASCII是没法忍受的”"><a href="#8-4-5-“不基于ASCII是没法忍受的”" class="headerlink" title="8.4.5. “不基于ASCII是没法忍受的”"></a>8.4.5. “不基于ASCII是没法忍受的”</h3><p>是的，如果我们可以直接读出协议内容，那么调试和追踪都会变得更为简单。但是基于文本的协议更容易产生错误，造成更多解析的问题。</p><p>假如你真的无法接受二进制协议，那么你也很难在HTTP 1.x中处理TLS和压缩。因为其实这些技术已经被使用了很久了。</p><h3 id="8-4-6-“它根本没有比HTTP-1-1快”"><a href="#8-4-6-“它根本没有比HTTP-1-1快”" class="headerlink" title="8.4.6. “它根本没有比HTTP/1.1快”"></a>8.4.6. “它根本没有比HTTP/1.1快”</h3><p>当然，到底该如何定义和衡量“快”就是另外一个话题了，但在SPDY的时代，已经有很多实验证明了该协议会让浏览器载入页面变得更快（例如华盛顿大学的<a href="https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-wang_xiao_sophia.pdf">“SPDY有多快？”</a>和Hervé Servy的<a href="https://www.neotys.com/blog/performance-of-spdy-enabled-web-servers/">“评估启用SPDY后的Web服务器的性能”</a>），同样这些实验也可以被用来证明http2。我期待能有越来越多的诸如此类的测试实验结果发布。而这篇文章<a href="https://blog.httpwatch.com/2015/01/16/a-simple-performance-comparison-of-https-spdy-and-http2/">httpwatch.com的一个简单测试</a>亦能证明HTTP/2名副其实。<!-- 那一句“我也期待XX”放在那怪怪的 --></p><h3 id="8-4-7-“它违反了网络分层”"><a href="#8-4-7-“它违反了网络分层”" class="headerlink" title="8.4.7. “它违反了网络分层”"></a>8.4.7. “它违反了网络分层”</h3><p>你确定这也是反对的理由么？网络分层并不是不可侵犯的。如果我们在制定http2的时候已经踏入了灰色地带，那我们当然可以尝试在限制内制定出更好更高效的协议。</p><h3 id="8-4-8-“它并没有修复很多HTTP-1-1的短板”"><a href="#8-4-8-“它并没有修复很多HTTP-1-1的短板”" class="headerlink" title="8.4.8. “它并没有修复很多HTTP/1.1的短板”"></a>8.4.8. “它并没有修复很多HTTP/1.1的短板”</h3><p>确实是这样。兼容HTTP/1.1的范式是我们的目标之一，所以一些老的HTTP功能仍然被保留。例如一些常用的协议头、可怕的cookies、验证头等等。但保留这些范式的好处就是我们在升级到新协议的时候少掉很多工作，也不需要重写很多底层的东西。Http2其实只是一个新的帧层。<!-- 那个"可怕的"cookies该怎么翻译好？ --></p><h2 id="8-5-http2会被广泛部署吗？"><a href="#8-5-http2会被广泛部署吗？" class="headerlink" title="8.5. http2会被广泛部署吗？"></a>8.5. http2会被广泛部署吗？</h2><p>现在讨论这个议题还言之尚早，但我仍然要在这里做出我的预估。</p><p>很多怀疑论者会以“看看IPv6现在的德性”为让我们回想起这个经历了10多年才开始慢慢被采用的协议。但http2毕竟不是IPv6。它是一个建立在TCP之上的使用基于原有HTTP协议升级过后的机制、端口号和TLS等的协议。大部分路由器或者防火墙不需要为此而进行更改。</p><p>Google向世界展示了他们的SPDY，证明了像这样的新协议也能在足够短的时间内拥有多种实现，并且能被浏览器和服务所采用。虽然如今支持SPDY服务器端数量在1%以内，但通过这些服务器所交换的数据却要大很多。很多非常流行的网站现在也有提供SPDY支持。</p><p>我认为建立在SPDY的基本范式之上的http2会被更广泛的部署，其中一个主要的原因是：它是一个IETF制定的协议。而SPDY则因为背负了“它是Google的协议”这个恶名，导致它的发展总是畏首畏脚。</p><p>在它首次发布的幕后有很多大型浏览器支持。来自Firefox，Chrome，Safari，Internet Explorer和Opera的代表宣布了他们会发布支持http2特性的浏览器，并且他们已经演示了一些能正常运作的实现。</p><p>也有很多像Google，Twitter和Facebook这样的服务器运营者希望尽快支持http2，也同样希望可以快点在主流服务器实现中出现对http2的支持（例如Apache HTTP Server和nginx）。而<a href="https://github.com/h2o/h2o">H2o</a>作为一个极具潜力的新生HTTP服务器，已经支持了http2。</p><p>那些大型代理程序开发者，例如HAProxy、Squid和Varnish也表示出了他们对支持http2的兴趣。</p><p>纵观2015年，http2的流量正在逐步上升。9月初，Firefox 40中http2流量占据了所有HTTP流量中的13%，HTTPS中的27%。与此同时，Google表示约有18%的流量来自HTTP/2。值得注意的是，Google同时也在实验其他协议，这也使得http2的使用量暂时比正常值低一些。</p><h1 id="9-Firefox里的http2"><a href="#9-Firefox里的http2" class="headerlink" title="9. Firefox里的http2"></a>9. Firefox里的http2</h1><p>Firefox紧跟着草案，并且很早之前就实现了http2的测试实现。在http2协议开发的时候，客户端和服务器需要采用同一的协议草案版本，进行测试也变得比较繁琐。所以请一定注意你的客户端和服务器支持的是一样的版本。</p><h2 id="9-1-首先，确保它已被启用"><a href="#9-1-首先，确保它已被启用" class="headerlink" title="9.1. 首先，确保它已被启用"></a>9.1. 首先，确保它已被启用</h2><p>从发布于2015年1月13日的Firefox 35之后，http2支持是默认开启的。</p><p>在地址栏里进入’about:config’，再搜索一个名为“network.http.spdy.enabled.http2draft”的选项，确保它被设置为<code>true</code>。Firefox 36添加了一个“network.http.spdy.enabled.http2”的配置项，并默认设置为<em>true</em>。后者控制的是“纯”http2版本，而前者控制了启用／禁用通过http2草案版本进行协商。从Firefox 36之后，这两者都默认为true。</p><h2 id="9-2-仅限TLS"><a href="#9-2-仅限TLS" class="headerlink" title="9.2. 仅限TLS"></a>9.2. 仅限TLS</h2><p>请记住Firefox只在TLS上实现了http2。你只会看到http2只在<code>https://</code>的网站里得到支持。</p><h2 id="9-3-透明！"><a href="#9-3-透明！" class="headerlink" title="9.3. 透明！ "></a>9.3. 透明！ <!--这个标题改成： 一切都是透明的  怎么样--></h2><p><img src="https://image.fyxemmmm.cn/blog/images/h210.png" alt="transparent http2 use"></p><p>在UI上，没有任何元素标明你正在使用http2。但想确认也并不复杂，一种方法是启用“Web developer-&gt;Network”，再查看响应头里面服务器发回来的内容。这个响应是“HTTP/2.0”，并且Firefox也插入了一个自己头“X-Firefox-Spdy:”，如上面截图所示。</p><p>你在这里看到的头文件是网络工具把二进制的http2格式转换成类似HTTP 1.x显示方式的文本格式。</p><h2 id="9-4-图形化HTTP-2"><a href="#9-4-图形化HTTP-2" class="headerlink" title="9.4. 图形化HTTP/2"></a>9.4. 图形化HTTP/2</h2><p>有一些Firefox的插件可以图形化HTTP/2，比如<a href="https://addons.mozilla.org/en-US/firefox/addon/http2-indicator/">“HTTP/2 and SPDY Indicator”</a>。</p><h1 id="10-Chromium里的http2"><a href="#10-Chromium里的http2" class="headerlink" title="10. Chromium里的http2"></a>10. Chromium里的http2</h1><p>Chromium团队并且很早之前就已经在dev和beta分支里面实现并支持了HTTP/2。从2015年1月27日发布的Chrome 40起，http2已经默认为一些用户启用该功能。虽然刚开始用户的数量会很少，但会慢慢增加。</p><p>Chrome 51移除了SPDY的支持来为http2铺路。在2016年2月的一篇<a href="https://blog.chromium.org/2016/02/transitioning-from-spdy-to-http2.html">博客</a>里面有如下一段话：</p><blockquote><p>“在Chrome里有超过25%的资源是通过HTTP/2来传输的，而SPDY只有不到5%。考虑到如此大范围的采用，自5月15日，也就是HTTP/2 RFC的周年纪念日起，Chrome将不再支持SPDY。”</p></blockquote><h2 id="10-1-首先，确保它已被启用"><a href="#10-1-首先，确保它已被启用" class="headerlink" title="10.1. 首先，确保它已被启用"></a>10.1. 首先，确保它已被启用</h2><p>在地址栏里进入<code>chrome://flags/#enable-spdy4</code>，如果没有被enable的话，点击”enable”启用它。</p><h2 id="10-2-TLS-only"><a href="#10-2-TLS-only" class="headerlink" title="10.2. TLS-only"></a>10.2. TLS-only</h2><p>请记住Chrome只在TLS上实现了http2。你只会在以<code>https://</code>做前缀的网站里得到http2的支持。</p><h2 id="10-3-图形化HTTP-2"><a href="#10-3-图形化HTTP-2" class="headerlink" title="10.3. 图形化HTTP/2"></a>10.3. 图形化HTTP/2</h2><p>有一些Chrome的插件可以图形化HTTP/2，比如<a href="https://chrome.google.com/webstore/detail/spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin">“HTTP/2 and SPDY Indicator”</a>。</p><h2 id="10-4-QUIC"><a href="#10-4-QUIC" class="headerlink" title="10.4. QUIC"></a>10.4. QUIC</h2><p>Chrome正在试验QUIC，所以或多或少稀释了HTTP/2的份额。</p><h1 id="11-curl中的http2"><a href="#11-curl中的http2" class="headerlink" title="11. curl中的http2"></a>11. curl中的http2</h1><p><a href="https://curl.haxx.se/">curl项目</a>从2013年9月就开始对http2提供实验性的支持。</p><p>为了遵从curl的要旨，我们尽可能全方位地支持http2。curl通常被用作一个网站连接测试工具，希望这项使命也能在http2上被得以延续。</p><p>curl使用一个叫做<a href="https://nghttp2.org/">nghttp2</a>的库来提供http2帧层的支持。curl依赖于nghttp2 1.0以上版本。</p><p>请注意当前linux curl和libcurl并没有默认启用对HTTP/2协议的支持。</p><h2 id="11-1-跟HTTP-1-x非常相似"><a href="#11-1-跟HTTP-1-x非常相似" class="headerlink" title="11.1. 跟HTTP 1.x非常相似"></a>11.1. 跟HTTP 1.x非常相似</h2><p>curl会在内部把收到的http2头部转换为HTTP1.x风格的头部再呈现给用户，这样一来，它们就和目前的HTTP非常类似。这也使得无论是用curl还是HTTP，转换都非常容易。<!-- TOREVIEW -->类似地，curl会用相同的方式对发出的HTTP头部做转换，即发给curl的HTTP 1.x风格头部会在被发送到http2服务器之前完成转换。这使得户无需关心底层到底使用的是哪个版本的HTTP协议。</p><h2 id="11-2-不安全的纯文本"><a href="#11-2-不安全的纯文本" class="headerlink" title="11.2. 不安全的纯文本"></a>11.2. 不安全的纯文本</h2><p>curl通过升级头部支持基于标准TCP的http2. 当发起一个使用http2的HTTP请求，如果可能，curl会请求服务器把连接升级到http2.</p><h2 id="11-3-TLS和相关库"><a href="#11-3-TLS和相关库" class="headerlink" title="11.3. TLS和相关库"></a>11.3. TLS和相关库</h2><p>curl可以使用许多不同TLS的底层库来提供TLS支持，http2也得这样。TLS兼容http2的挑战来自于对ALPN以及一些NPN扩展的支持。</p><p>基于最新版本的OpenSSL或NSS编译curl可以同时获得ALPN和NPN支持。而使用GnuTLS或PolarSSL只能得到ALPN。</p><h2 id="11-4-命令行中使用"><a href="#11-4-命令行中使用" class="headerlink" title="11.4. 命令行中使用"></a>11.4. 命令行中使用</h2><p>无论是用纯文本还是通过TLS，必须使用<code>--http2</code>参数来让curl使用http2。在未使用该参数的默认情况下，curl会使用HTTP/1.1。</p><h2 id="11-5-libcurl参数"><a href="#11-5-libcurl参数" class="headerlink" title="11.5. libcurl参数"></a>11.5. libcurl参数</h2><h3 id="11-5-1-启用HTTP-2"><a href="#11-5-1-启用HTTP-2" class="headerlink" title="11.5.1 启用HTTP/2"></a>11.5.1 启用HTTP/2</h3><p>应用程序和从前一样使用<code>https://</code>或者<code>http://</code>风格的URL，但你可以通过将<code>curl_easy_setopt</code>的<code>SURLOPT_HTTP_VERSION</code>参数设置为<code>CURL_HTTP_VERSION_2</code>来使libcurl尝试使用http2。它将优先尽可能地使用http2，如果不行的话，会继续使用HTTP 1.1。</p><h3 id="11-5-2-多路复用"><a href="#11-5-2-多路复用" class="headerlink" title="11.5.2 多路复用"></a>11.5.2 多路复用</h3><p>正如libcurl想尽可能量维持以前的用法，你需要通过<a href="https://curl.haxx.se/libcurl/c/CURLMOPT_PIPELINING.html">CURLMOPT_PIPELINING</a>参数为你的程序启用HTTP/2多路复用功能。不然的话，它会保持一个连接只发送一个请求。</p><p>另一个需要注意的小细节是，当你通过libcurl同时请求多个传输的时候，请使用多接口模式。这样能使应用程序能同时启用任意数量的传输。如果你宁愿让libcurl等待也要把它们放到同一个连接来传输的话，请使用<a href="https://curl.haxx.se/libcurl/c/CURLOPT_PIPEWAIT.html">CURLOPT_PIPEWAIT</a>参数。</p><h3 id="11-5-3-服务器推送"><a href="#11-5-3-服务器推送" class="headerlink" title="11.5.3 服务器推送"></a>11.5.3 服务器推送</h3><p>libcurl 7.44.0及其后续版本开始支持HTTP/2服务器推送功能。你可以通过在<a href="https://curl.haxx.se/libcurl/c/CURLMOPT_PUSHFUNCTION.html">CURLMOPT_PUSHFUNCTION</a>参数中设定一个推送回调来激活该功能。如果应用程序接受了该推送，它将为CURL建立一个新的传输，以便接受内容。<!-- 最后一句需要review --></p>]]></content>
      
      
      <categories>
          
          <category> 协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> http2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>http2详解 [中]</title>
      <link href="/2021/08/25/http2-xiang-jie-zhong/"/>
      <url>/2021/08/25/http2-xiang-jie-zhong/</url>
      
        <content type="html"><![CDATA[<h1 id="5-http2的基本概念"><a href="#5-http2的基本概念" class="headerlink" title="5. http2的基本概念"></a>5. http2的基本概念</h1><p>http2到底做了些什么呢？而HTTPbis小组究竟又应该把它制定到什么样的程度呢？</p><p>事实上，http2有着非常严格的边界，这也给小组成员的创新带来了些许限制。</p><ul><li><p>http2必须维持HTTP的范式。毕竟它只是一个让客户端发送请求到服务器的基于TCP的协议。</p></li><li><p>不能改变 http:// 和 https:// 这样的URL，也不能对其添加新的结构。使用这类URL的网站太多了，没法指望他们全部改变。</p></li><li><p>HTTP1的服务器和客户端依然会存在很久，所以我们必须提供HTTP1到http2服务器的代理。</p></li><li><p>随后，我们也要让这种代理能够将http2的功能一对一的映射到HTTP 1.1的客户端。</p></li><li><p>删除或者减少协议里面那些可选的部分。虽然这并不算的上是一个需求，但是SPDY和Google的团队都非常喜欢这点。通过让协议里所有的内容都成为了强制性要求，可以防止人们在实现的时候偷懒，从而规避一些将来可能会发生的问题。</p></li><li><p>不再使用小版本号。服务器和客户端都必须确定自己是否完整兼容http2或者彻底不兼容。如果将来该协议需要被扩充或者变更，那么新的协议将会是http3，而不是http 2.x。</p></li></ul><h2 id="5-1-http2和现有的URI结构"><a href="#5-1-http2和现有的URI结构" class="headerlink" title="5.1. http2和现有的URI结构"></a>5.1. http2和现有的URI结构</h2><p>如上所述，现有的URI结构正在被HTTP 1.x使用而不能被更换，所以http2也必须沿用该结构。因此不得不找到一种方式将使用的协议升级至http2，比如可以要求服务器让它作响应时使用http2来替代旧的协议。</p><p>HTTP 1.1本身就制定过“升级”的方案：提供一个首部字段，表示允许服务器在收到旧协议请求的同时，可以向客户端发送新协议的响应。但这一方案往往需要花费一次额外的往返通信来作为升级的代价。</p><p>而这一代价是SPDY团队不想接受的。因为他们只实现了基于TLS的SPDY，所以他们开发了一个TLS的扩展去简化协议的协商。这个扩展被称作NPN（Next Protocol Negotiation），借助于此，服务器会通知客户端所有它支持的协议，让客户端从中选择一个合适的来进行通讯。</p><h2 id="5-2-为-https-所准备的http2"><a href="#5-2-为-https-所准备的http2" class="headerlink" title="5.2. 为 https:// 所准备的http2"></a>5.2. 为 https:// 所准备的http2<!--这节比较复杂，需要review--></h2><p>有相当多的人关注到了http2可以在TLS上正常的运作，而SPDY依赖于TLS，所以按理说TLS也应成为http2 必需的组件，不过出乎大家意料的是http2将TLS标记成了可选。然而，全球两大浏览器领导者 —— Firefox和Chrome都明确地表示，他们只会实现基于TLS的http2.</p><p>选择TLS的原因的其中之一是希望保护以及尊重用户的隐私，而早期的评估结果也表明，在TLS上建立新的协议更有可能获得成功。而这其中部分原因是人们普遍认为任何来自80端口的流量都是基于HTTP 1.1亦或者是其某个变种的，而不是另外一种全新的协议。</p><p>关于是否应该强制使用TLS的主题在邮件组内和会议上引起了不小的争议 —— 这到底是好是坏呢？不管怎么样，对于这种备受争议的话题还是请谨慎讨论，尤其是当你面对一个HTTPbis小组成员的时候。</p><p>诸如此类，还有一个激烈而长期的讨论，即：如果选择了使用TLS，那http2是否应该强制规定密码列表，也许应该建立起一个黑名单，又或者它根本就不需要从TLS层得到任何东西。不过这个问题还是留给TLS工作组去解决吧，最后的规范中指定了TLS最低版本为1.2，并且会有加密组的限制。</p><h2 id="5-3-基于TLS之上的http2协商"><a href="#5-3-基于TLS之上的http2协商" class="headerlink" title="5.3 基于TLS之上的http2协商 "></a>5.3 基于TLS之上的http2协商 <!-- 这个标题翻译的不好 --></h2><p>Next Protocol Negotiation (NPN)是一个用来在TLS服务器上协商SPDY的协议。IETF将这个非正式标准进行规范化，从而演变成了ALPN（Application Layer Protocol Negotiation）。ALPN会随着http2的应用被推广，而SPDY的客户端与服务器则会继续使用NPN。</p><p>由于NPN先于ALPN诞生，而ALPN又经历了一些标准化过程，所以许多早期的http2客户端和服务器在协商http2时会将这两者同时实现。与此同时，考虑到SPDY会使用NPN，而许多服务器又会同时提供SPDY以及http2，所以在这些服务器上同时支持ALPN以及NPN显然会成为最理所当然的选择。</p><p>ALPN和NPN的主要区别在于：谁来决定通信协议。在ALPN的描述中，是让客户端先发送一个协议优先级列表给服务器，由服务器最终选择一个合适的。而NPN则正好相反，客户端有着最终的决定权。</p><h2 id="5-4-为-http-所准备的http2"><a href="#5-4-为-http-所准备的http2" class="headerlink" title="5.4 为 http:// 所准备的http2"></a>5.4 为 http:// 所准备的http2</h2><p>正如我们之前所提到的，对于纯文本的HTTP1.1来说，协商http2的方法就是通过给服务器发送一个带<strong>升级</strong>头部的报文。如果服务器支持http2，它将以“101 Switching”作为回复的状态码，并从此开始在该连接上使用http2。也许你很容易就发现这样一个升级的流程会需要消耗掉一整个的往返时延，但好处是http2连接相比HTTP1可以被更大限度地重用和保持。</p><p>虽然有些浏览器厂商的发言人宣称他们不会实现这样的http2会话方式，但IE团队已公开表示他们会实现，与此同时，curl也已经支持了这种方式。</p><p>直到今天，没有任何主流浏览器支持非TLS的http2.</p><h1 id="6-http2协议"><a href="#6-http2协议" class="headerlink" title="6. http2协议"></a>6. http2协议</h1><p>背景介绍就到此为止了，历史的脚步已经将我们推到了今天。现在让我们深入看看该协议的规范，看看那些细节和概念。</p><h2 id="6-1-二进制"><a href="#6-1-二进制" class="headerlink" title="6.1. 二进制"></a>6.1. 二进制</h2><p>http2是一个二进制协议。</p><p>仔细想想，如果你是一个曾经跟互联网协议打过交道，那你很可能会本能反对二进制协议，你甚至准备好了一大堆理由来证明基于文本/ascii的协议是多么的有用，正如你曾无数次地通过telnet等应用手工地输入HTTP来发起请求。</p><p>基于二进制的http2可以使成帧的使用变得更为便捷。在HTTP1.1和其他基于文本的协议中，对帧的起始和结束识别起来相当复杂。而通过移除掉可选的空白符以及其他冗余后，再来实现这些会变得更容易。</p><p>而另一方面，这项决议同样使得我们可以更加便捷的从帧结构中分离出那部分协议本身的内容。而在HTTP1中，各个部分相互交织，犹如一团乱麻。</p><p>事实上，由于协议提供了压缩这一特性，而其经常运行在TLS之上的事实又再次降低了基于纯文本实现的价值，反正也没办法直接从数据流上看到文本。因此通常情况下，我们必须习惯使用类似Wireshark这样的工具对http2的协议层一探究竟。</p><p>我们可以使用curl这样的工具来调试协议，而如果要进一步地分析网络数据流则需要诸如Wireshark这样的http2解析器。</p><h2 id="6-2-二进制格式"><a href="#6-2-二进制格式" class="headerlink" title="6.2. 二进制格式"></a>6.2. 二进制格式</h2><img style="float: right;" src="https://image.fyxemmmm.cn/blog/images/h26.png"><p>http2会发送有着不同类型的二进制帧，但他们都有如下的公共字段：Type, Length, Flags, Stream Identifier和frame payload <!-- 这些字段要翻译么？ --></p><p>规范中一共定义了10种不同的帧，其中最基础的两种分别对应于HTTP 1.1的DATA和HEADERS。之后我会更详细的介绍它们其中的一部分。</p><h2 id="6-3-多路复用的流"><a href="#6-3-多路复用的流" class="headerlink" title="6.3. 多路复用的流"></a>6.3. 多路复用的流</h2><p>上一节提到的Stream Identifier将http2连接上传输的每个帧都关联到一个“流”。流是一个独立的，双向的帧序列可以通过一个http2的连接在服务端与客户端之间不断的交换数据。<!-- 这一句翻译的不太好。 --></p><p>每个单独的http2连接都可以包含多个并发的流，这些流中交错的包含着来自两端的帧。流既可以被客户端/服务器端单方面的建立和使用，也可以被双方共享，或者被任意一边关闭。在流里面，每一帧发送的顺序非常关键。接收方会按照收到帧的顺序来进行处理。</p><p>流的多路复用意味着在同一连接中来自各个流的数据包会被混合在一起。就好像两个（或者更多）独立的“数据列车”被拼凑到了一辆列车上，但它们最终会在终点站被分开。下图就是两列“数据火车”的示例</p><p><img src="https://image.fyxemmmm.cn/blog/images/h27.jpg" alt="one train"><br><img src="https://image.fyxemmmm.cn/blog/images/h28.jpg" alt="another train"></p><p>它们就是这样通过多路复用的方式被组装到了同一列火车上。</p><p><img src="https://image.fyxemmmm.cn/blog/images/h29.jpg" alt="multiplexed train"></p><h2 id="6-4-优先级和依赖性"><a href="#6-4-优先级和依赖性" class="headerlink" title="6.4. 优先级和依赖性"></a>6.4. 优先级和依赖性</h2><p>每个流都包含一个优先级（也就是“权重”），它被用来告诉对端哪个流更重要。当资源有限的时候，服务器会根据优先级来选择应该先发送哪些流。</p><p>借助于PRIORITY帧，客户端同样可以告知服务器当前的流依赖于其他哪个流。该功能让客户端能建立一个优先级“树”，所有“子流”会依赖于“父流”的传输完成情况。</p><p>优先级和依赖关系可以在传输过程中被动态的改变。这样当用户滚动一个全是图片的页面的时候，浏览器就能够指定哪个图片拥有更高的优先级。或者是在你切换标签页的时候，浏览器可以提升新切换到页面所包含流的优先级。 <!--或者是当你在切换标签页的时候，浏览器可以提升那个突然被切换到的页面所包含的流的优先级--></p><h2 id="6-5-头压缩"><a href="#6-5-头压缩" class="headerlink" title="6.5. 头压缩"></a>6.5. 头压缩</h2><p>HTTP是一种无状态的协议。简而言之，这意味着每个请求必须要携带服务器需要的所有细节，而不是让服务器保存住之前请求的元数据。因为http2并没有改变这个范式，所以它也以同样原理工作。</p><p>这也保证了HTTP可重复性。当一个客户端从同一服务器请求了大量资源（例如页面的图片）的时候，所有这些请求看起来几乎都是一致的，而这些大量一致的东西则正好值得被压缩。</p><p>每个页面请求的资源数量在增多（如前所述），同时 cookies 的使用和请求的大小也在日渐增长。cookies需要被包含在所有请求中，且他们在多个请求中经常是一模一样的。</p><p>HTTP 1.1请求的大小正变得越来越大，有时甚至会大于TCP窗口的初始大小，这会严重拖累发送请求的速度。因为它们需要等待带着ACK的响应回来以后，才能继续被发送。这也是另一个需要压缩的理由。</p><h3 id="6-5-1-压缩是非常棘手的课题"><a href="#6-5-1-压缩是非常棘手的课题" class="headerlink" title="6.5.1. 压缩是非常棘手的课题"></a>6.5.1. 压缩是非常棘手的课题</h3><p>HTTPS和SPDY的压缩机制被发现有受<a href="https://en.wikipedia.org/wiki/BREACH_%28security_exploit%29">BREACH</a>和<a href="https://en.wikipedia.org/wiki/CRIME">CRIME</a>攻击的隐患。通过向流中注入一些已知的文本来观察输出的变化，攻击者可以从加密的载荷中推导出原始发送的数据。</p><p>为协议的动态内容进行压缩并使其免于被攻击，需要仔细且全面的考虑，而这也正是HTTPbis小组尝试去做的。</p><p><a href="https://www.rfc-editor.org/rfc/rfc7541.txt">HPACK</a>，HTTP/2头部压缩，顾名思义它是一个专为http2头部设计的压缩格式。确切的讲，它甚至被制定写入在另外一个单独的草案里。新的格式同时引入了一些其他对策让破解压缩变得困难，例如采用帧的可选填充和用一个bit作为标记，来让中间人不压缩指定的头部。<!-- 最后这句不太好 --> <!--这里中间人翻译成代理会不会更好，中间人一般都会自然联想到MITM攻击（比如我...）--></p><p>用Roberto Peon（HPACK的设计者之一）的话说</p><blockquote><p>“HPACK旨在提供一个一致性的实现使信息量的损失尽可能少，使编解码快速而方便，使接收方能控制压缩文本的大小，允许代理重新建立索引（如，通过代理在前后端共享状态），以及对哈夫曼编码串的更快速比较”<!-- 这一段需要review --></p></blockquote><h2 id="6-6-重置-后悔药"><a href="#6-6-重置-后悔药" class="headerlink" title="6.6. 重置 - 后悔药"></a>6.6. 重置 - 后悔药<!-- 这个翻译太别扭了。。--></h2><p>HTTP 1.1的有一个缺点是：当一个含有确切值的Content-Length的HTTP消息被送出之后，你就很难中断它了。当然，通常你可以断开整个TCP链接（但也不总是可以这样），但这样导致的代价就是需要通过三次握手来重新建立一个新的TCP连接。</p><p>一个更好的方案是只终止当前传输的消息并重新发送一个新的。在http2里面，我们可以通过发送RST_STREAM帧来实现这种需求，从而避免浪费带宽和中断已有的连接。</p><h2 id="6-7-服务器推送"><a href="#6-7-服务器推送" class="headerlink" title="6.7. 服务器推送"></a>6.7. 服务器推送</h2><p>这个功能通常被称作“缓存推送”。主要的思想是：当一个客户端请求资源X，而服务器知道它很可能也需要资源Z的情况下，服务器可以在客户端发送请求前，主动将资源Z推送给客户端。这个功能帮助客户端将Z放进缓存以备将来之需。</p><p>服务器推送需要客户端显式的允许服务器提供该功能。但即使如此，客户端依然能自主选择是否需要中断该推送的流。如果不需要的话，客户端可以通过发送一个RST_STREAM帧来中止。</p><h2 id="6-8-流量控制"><a href="#6-8-流量控制" class="headerlink" title="6.8. 流量控制"></a>6.8. 流量控制</h2><p>每个http2流都拥有自己的公示的流量窗口，它可以限制另一端发送数据。如果你正好知道SSH的工作原理的话，这两者非常相似。</p><p>对于每个流来说，两端都必须告诉对方自己还有足够的空间来处理新的数据，而在该窗口被扩大前，另一端只被允许发送这么多数据。</p><p>而只有数据帧会受到流量控制。</p><h1 id="7-扩展"><a href="#7-扩展" class="headerlink" title="7. 扩展"></a>7. 扩展</h1><p>http2协议强制规定了接收方必须读取并忽略掉所有未知帧（即未知帧类型的帧）。双方可以在逐跳原则（hop-by-hop basis）基础上协商使用新的帧，但这些帧的状态无法被改变，也不受流控制。</p><p>是否应该允许添加扩展的这个话题在制定http2协议的时候被反复讨论了很久，但在draft-12之后，最终尘埃落定确定了允许添加扩展。</p><p>但扩展不再是协议本身的一部分，它被记录在核心协议规范之外。现在已经有两种类型的帧被工作组记录在案，它们很可能率先被纳入协议的扩展部分，而这两个曾被当作“原生”的帧非常流行，所以接下来我会详细讨论它们。</p><h2 id="7-1-备选服务（Alternative-Services）"><a href="#7-1-备选服务（Alternative-Services）" class="headerlink" title="7.1. 备选服务（Alternative Services）"></a>7.1. 备选服务（Alternative Services）</h2><p>随着http2逐渐被接受，我们有理由相信，相对于HTTP 1.x，TCP连接会更长并被保持的更久。对客户端来讲，最好是到每个主机/站点的每一条连接都可以做尽可能多的事情，而这也需要每个连接可以保持更长的时间。</p><p>但这会影响到HTTP负载均衡器的正常工作，比如在一个网站会出于性能的考虑，当然也可能是正常的维护或者一些类似的原因，想建议客户端连接到另外一个主机的时候。<!-- 这一段需要review --></p><p>服务器将会通过发送<a href="https://tools.ietf.org/html/draft-ietf-httpbis-alt-svc-10">Alt-Svc头</a>（或者http2的ALTSVC帧）来告知客户端另一个备选服务。即另外一条指向不同的服务源、主机或端口，但却能获取同样内容的路由。</p><p>客户端应该尝试异步的去连接到该服务，如果连接成功的话，即可以使用该备选服务。<!-- 这一段需要review --></p><h3 id="7-1-1-机会型TLS（Opportunistic-TLS）"><a href="#7-1-1-机会型TLS（Opportunistic-TLS）" class="headerlink" title="7.1.1. 机会型TLS（Opportunistic TLS）"></a>7.1.1. 机会型TLS（Opportunistic TLS）</h3><p>Alt-Svc头部意味着允许服务器基于<code>http://</code>提供内容，与此同时，这个头部也意味着告知客户端：同样的内容也可以通过TLS连接来获取。</p><p>这是个还在讨论中的功能。因为这样的连接会产生一个未认证的、在任何地方也不会被标示为“安全”的TLS连接，也不会在客户端界面上出现任何锁标识，所以没法让用户知道这其实不是常规的HTTP连接。这就是很多人强烈反对机会型TLS的原因。</p><h2 id="7-2-阻塞（Blocked）"><a href="#7-2-阻塞（Blocked）" class="headerlink" title="7.2. 阻塞（Blocked）"></a>7.2. 阻塞（Blocked）</h2><p>这个类型的帧意味着：当服务端存在需要发送的内容，但流控制却禁止发送任何数据时，那么此类型的帧将会被发送且<strong>仅</strong>发送一次。这种帧设计的目的在于，如果你接收到了此帧，那么连接中必然有错误发生或者是得到了低于期望的传输速度。<!-- 这一段需要review --></p><p>在此帧被放到协议扩展部分之前，draft-12中的一段话：</p><blockquote><p>”阻塞帧被包含在草案版本中作为实验性的特性，如果它无法获得良好的反馈，那么该特性最后会被移除。”</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> http2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>http2详解 [上]</title>
      <link href="/2021/08/24/http2-xiang-jie-shang/"/>
      <url>/2021/08/24/http2-xiang-jie-shang/</url>
      
        <content type="html"><![CDATA[<h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h1><p>这篇文档会从技术和协议层面来介绍http2。</p><p>如果你有在这篇文章中发现任何我的失误造成的错误或疏漏，请帮我指正。我会在后续版本中修改。</p><p>为了让阅读体验更流畅，在这篇文章中我会使用“http2”来指代这一新协议，但请记住该协议的正式名字是HTTP/2。</p><hr><h1 id="2-HTTP的现状"><a href="#2-HTTP的现状" class="headerlink" title="2. HTTP的现状"></a>2. HTTP的现状</h1><p>几乎所有互联网上的内容都采用了HTTP 1.1作为通信协议。人们在该协议上投入了大量精力，所以基于它的基础架构也得以日臻完善。而得益于此，在现有的HTTP协议之上构建新的方案会比从底层建立新的协议要容易得多。</p><h2 id="2-1-HTTP-1-1过于庞大"><a href="#2-1-HTTP-1-1过于庞大" class="headerlink" title="2.1 HTTP 1.1过于庞大"></a>2.1 HTTP 1.1过于庞大</h2><p>HTTP刚诞生的时候只被当作是一个相对简单直观的协议，但时间证明了早期的设计并不尽人意。于1996年发布的、描述HTTP 1.0规范的RFC 1945只有60页，但仅仅3年之后、描述HTTP 1.1规范的RFC 2616就一下增长到了176页。而当我们在IETF小组对该规范进行更新时，它更是被拆分成了总页数更多的六个文档（这就是RFC 7230及其文件族的由来与诞生）。总而言之，HTTP 1.1包含了太多细节和可选的部分，这让它变得过于庞大。</p><h2 id="2-2-过多的可选项"><a href="#2-2-过多的可选项" class="headerlink" title="2.2 过多的可选项"></a>2.2 过多的可选项</h2><p>HTTP 1.1不仅包含了非常多的细枝末节，同时也为未来的扩展预留了很多选项。这种事无巨细的风格导致在现有的软件生态中，几乎没有任何实现真正实现了协议中提及的所有细节，甚至要弄清楚“所有细节”到底包括哪些细节都非常困难。而这也导致了很多最初不常用的功能在后来的实现中很少会被支持，而有些最初实现了的功能，却又很少被使用。</p><p>随着时间推移，这些当初看似被边缘化的功能逐渐被用上，客户端和服务器的互用性（interoperability）问题就被暴露了出来。HTTP管线化（HTTP pipelining）就是一个非常好的例子。</p><h2 id="2-3-未能被充分利用的TCP"><a href="#2-3-未能被充分利用的TCP" class="headerlink" title="2.3 未能被充分利用的TCP"></a>2.3 未能被充分利用的TCP</h2><p>HTTP 1.1很难榨干TCP协议所能提供的所有性能。HTTP客户端和浏览器必须要另辟蹊径的去找到新的解决方案来降低页面载入时间。</p><p>与此同时，人们也尝试去用新的协议来替代TCP，但结果证明这也非常困难。无奈之下，我们只能尝试同时改进TCP协议本身和基于TCP的上层协议。</p><p>简单来说，我们可以通过更好的利用TCP来减少传输过程中的暂停，并充分挖掘利用那些本可以用于发送/接受更多数据的时间。下面几段我们将会着重讨论这些问题。</p><h2 id="2-4-传输大小和资源数量"><a href="#2-4-传输大小和资源数量" class="headerlink" title="2.4 传输大小和资源数量"></a>2.4 传输大小和资源数量</h2><p>如果仔细观察打开那些最流行的网站首页所需要下载的资源的话，会发现一个非常明显的趋势。  近年来加载网站首页需要的下载的数据量在逐渐增加，并已经超过了1.9MB。但在这里我们更应该关心的是：平均每个页面为了完成显示与渲染所需要下载的资源数已经超过了100个。</p><p>正如下图所示，这种趋势已经持续了很长一段时间，并且没有减缓的迹象。该图表中绿色直线展示了传输数据大小的增长，红色直线展示了平均请求资源数量的增长。</p><p><img src="https://image.fyxemmmm.cn/blog/images/h21.png" alt="transfer size growth"></p><h2 id="2-5-恼人的延迟"><a href="#2-5-恼人的延迟" class="headerlink" title="2.5 恼人的延迟"></a>2.5 恼人的延迟</h2><img style="float: right;" src="https://image.fyxemmmm.cn/blog/images/h22.png"><p>HTTP 1.1对网络延迟非常敏感。部分原因是HTTP pipelining还存有很多问题，所以对大部分用户来说这项技术是被默认关闭的。</p><p>虽然近几年来网络带宽增长非常快，然而我们却并没有看到网络延迟有对应程度的降低。在高延迟的网络上（比如移动设备），即使拥有高连接速率，也很难获得优质快速的网络体验。</p><p>另外一个需要低延迟的场景是某些视频服务，如视频会议、游戏和一些类似无法预生成待发送数据流的服务。</p><h2 id="2-6-线头阻塞（Head-of-line-blocking）"><a href="#2-6-线头阻塞（Head-of-line-blocking）" class="headerlink" title="2.6 线头阻塞（Head-of-line blocking）"></a>2.6 线头阻塞（Head-of-line blocking）</h2><p>HTTP pipelining是这样一种技术：在等待上一个请求响应的同时，发送下一个请求。(译者注：作者这个解释并不完全正确，HTTP pipelining其实是把多个HTTP请求放到一个TCP连接中一一发送，而在发送过程中不需要等待服务器对前一个请求的响应；只不过，客户端还是要按照发送请求的顺序来接收响应。)但就像在超市收银台或者银行柜台排队时一样，你并不知道前面的顾客是干脆利索的还是会跟收银员/柜员磨蹭到世界末日（译者注：不管怎么说，服务器（即收银员/柜员）是要按照顺序处理请求的，如果前一个请求非常耗时（顾客磨蹭），那么后续请求都会受到影响），这就是所谓的线头阻塞（head-of-line blocking）。</p><img style="float: right;" src="https://image.fyxemmmm.cn/blog/images/h23.png"><p>当然，你可以在选择队伍时候就做好功课，去排一个你认为最快的队伍，或者甚至另起一个新的队伍（译者注：即新建一个TCP连接）。但不管怎么样，你总归得先选择一个队伍，而且一旦选定之后，就不能更换队伍。</p><p>但是，另起新队伍会导致资源耗费和性能损失（译者注：新建 TCP 连接的开销非常大）。这种另起新队伍的方式只在新队伍数量很少的情况下有作用，因此它并不具备可扩展性。（译者注：这段话意思是说，靠大量新建连接是不能有效解决延迟问题的，即HTTP pipelining并不能彻底解决head-of-line blocking问题。）所以针对此问题并没有完美的解决方案。</p><p>这就是为什么即使到了今天，大部分桌面浏览器仍然会选择默认关闭HTTP pipelining这一功能的原因。</p><p>而关于这个问题的更多细节，可以参阅Firefox的 <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=264354">bugzilla #264354</a>。</p><h1 id="3-那些年，克服延迟之道"><a href="#3-那些年，克服延迟之道" class="headerlink" title="3. 那些年，克服延迟之道"></a>3. 那些年，克服延迟之道</h1><p>再困难的问题也有解决的方案，但这些方案却良莠不齐。</p><h2 id="3-1-Spriting"><a href="#3-1-Spriting" class="headerlink" title="3.1 Spriting"></a>3.1 Spriting</h2><img style="float: right;" src="https://image.fyxemmmm.cn/blog/images/h24.jpg"><p>Spriting是一种将很多较小的图片合并成一张大图，再用JavaScript或者CSS将小图重新“切割”出来的技术。</p><p>网站可以利用这一技巧来达到提速的目的——在HTTP 1.1里，下载一张大图比下载100张小图快得多。</p><p>但是当某些页面只需要显示其中一两张小图时，这种缓存整张大图的方案就显得过于臃肿。同时，当缓存被清楚的时候的时候，Spriting会导致所有小图片被同时删除，而不能选择保留其中最常用的几个。</p><h2 id="3-2-内联（Inlining）"><a href="#3-2-内联（Inlining）" class="headerlink" title="3.2 内联（Inlining）"></a>3.2 内联（Inlining）</h2><p>Inlining是另外一种防止发送很多小图请求的技巧，它将图片的原始数据嵌入在CSS文件里面的URL里。而这种方案的优缺点跟Spriting很类似。</p><pre><code>.icon1 {    background: url(data:image/png;base64,&lt;data&gt;) no-repeat;  }.icon2 {    background: url(data:image/png;base64,&lt;data&gt;) no-repeat;  }</code></pre><h2 id="3-3-拼接（Concatenation）"><a href="#3-3-拼接（Concatenation）" class="headerlink" title="3.3 拼接（Concatenation）"></a>3.3 拼接（Concatenation）</h2><p>大型网站往往会包含大量的JavaScript文件。开发人员可以利用一些前端工具将这些文件合并为一个大的文件，从而让浏览器能只花费一个请求就将其下载完，而不是发无数请求去分别下载那些琐碎的JavaScript文件。但凡事往往有利有弊，如果某页面只需要其中一小部分代码，它也必须下载完整的那份；而文件中一个小小的改动也会造成大量数据的被重新下载。</p><p>这种方案也给开发者造成了很大的不便。</p><h2 id="3-4-分片（Sharding）"><a href="#3-4-分片（Sharding）" class="headerlink" title="3.4 分片（Sharding）"></a>3.4 分片（Sharding）</h2><p>最后一个我要说的性能优化技术叫做“Sharding”。顾名思义，Sharding就是把你的服务分散在尽可能多的主机上。这种方案乍一听比较奇怪，但是实际上在这背后却蕴藏了它独辟蹊径的道理！</p><p>最初的HTTP 1.1规范提到一个客户端最多只能对同一主机建立两个TCP连接。因此，为了不和规范冲突，一些聪明的网站使用了新的主机名，这样的话，用户就能和网站建立更多的连接，从而降低载入时间。</p><p>后来，两个连接的限制被取消了，现在的客户端可以轻松地和每个主机建立6-8个连接。但由于连接的上限依然存在，所以网站还是会用这种技术来提升连接的数量。而随着资源个数的提升（上面章节的图例），网站会需要更多的连接来保证HTTP协议的效率，从而提升载入速度。在现今的网站上，使用50甚至100个连接来打开一个页面已经并不罕见。根据<a href="https://httparchive.org/">httparchive.org</a>的最新记录显示，在Top 30万个URL中平均使用40（！）个TCP连接来显示页面，而且这个数字仍然在缓慢的增长中。</p><p>另外一个将图片或者其他资源分发到不同主机的理由是可以不使用cookies，毕竟现今cookies的大小已经非常可观了。无cookies的图片服务器往往意味着更小的HTTP请求以及更好的性能！</p><p>下面的图片展示了访问一个瑞典著名网站的时产生的数据包，请注意这些请求是如何被分发到不同主机的。</p><p><img src="https://image.fyxemmmm.cn/blog/images/h25.jpg" alt="image sharding at expressen.se"></p><h1 id="4-升级HTTP"><a href="#4-升级HTTP" class="headerlink" title="4. 升级HTTP"></a>4. 升级HTTP</h1><p>花点功夫去改善HTTP协议显然是极好的事情。我们可以着手于以下几个方面：</p><ol><li>降低协议对延迟的敏感</li><li>修复pipelining和head of line blocking的问题</li><li>防止主机需求更高的连接数量</li><li>保留所有现有的接口，内容，URI格式和结构</li><li>由IETF的HTTPbis工作组来制定  <!-- 这一段有点莫名其妙 --></li></ol><h2 id="4-1-IETF和HTTPbis工作组"><a href="#4-1-IETF和HTTPbis工作组" class="headerlink" title="4.1. IETF和HTTPbis工作组"></a>4.1. IETF和HTTPbis工作组</h2><p>The Internet Engineering Task Force (IETF)是一个开发和推广互联网标准的组织。他们的重心是在协议层面。他们最出名的工作是制定了TCP、DNS、FTP和它们最佳实践的RFC规范，但HTTP和许多其他协议却进展缓慢。<!-- 最后一句话不太好 --></p><p>IETF成立了独立的“工作小组”以便完成某些特定领域内的目标，他们建立了一个“章程”用以制定达到目标的指导方针和规范。在这里，任何人都可以参与讨论和开发，并且每个人有同等的话语权，没人关心你来自哪个公司或组织。</p><p>HTTPbis工作组（我们待会儿再解释这个名字）在2007年夏天成立之后就着手于HTTP1.1标准的更新。在组内，关于下一版本HTTP协议的讨论实际上在2012年后期才开始。而HTTP1.1的更新工作在2014年初完成，并被整理成<a href="https://tools.ietf.org/html/rfc7320">RFC 7320</a>系列。</p><p>2014年6月初，HTTPbis工作组名义上的最终版文档会议在纽约召开。而剩下的讨论以及等IETF走完流程通过官方的RFC版本预计在来年完成。<!-- 这一段有点别扭 --> <!-- 而余下的讨论以及IETF流程会等到正式通过官方的RFC版本后继续，并预计来年完成。  不太确定这样翻好不好 --></p><p>一些HTTP领域的权威缺席了工作组的讨论和会议。我并不想在此提及任何公司和产品。但藉此，现在互联网上也有一些参与者因此获得了更多信心——不需要这些公司参与IETF也能做得很好。。。  </p><h3 id="4-1-1-名字中的“bis”"><a href="#4-1-1-名字中的“bis”" class="headerlink" title="4.1.1. 名字中的“bis”"></a>4.1.1. 名字中的“bis”</h3><p>工作组名字中的“bis”来自拉丁语中表示<a href="https://en.wiktionary.org/wiki/bis#Latin">“二”</a>的副词，Bis通常被IETF用作名字的后缀来以表示标准的升级或者一些二次工作，比如这里是针对HTTP1.1。</p><h2 id="4-2-起源于SPDY的http2"><a href="#4-2-起源于SPDY的http2" class="headerlink" title="4.2. 起源于SPDY的http2"></a>4.2. 起源于SPDY的http2</h2><p><a href="https://en.wikipedia.org/wiki/SPDY">SPDY</a>是由Google牵头开发的协议。他们将其开源，使得每个人都可以参与开发。但很明显，他们通过控制浏览器的实现和享用着优质服务的大量用户来获益。<!-- 这一句段翻译的怪怪的 --></p><p>当HTTPbis小组决定开始制定http2的时候，SPDY已经充分证实了它是一个非常好用的方案。当时已经有人在互联网上成功部署SPDY，并且也有一些文章讨论他的性能。因此，http2便基于SPDY/3草案进行一些修改之后发布了http2的draft-00。</p><!-- Review备注：有几段怪怪的，已标出 -->]]></content>
      
      
      <categories>
          
          <category> 协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> http2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自签CA &amp; 证书申请</title>
      <link href="/2021/08/20/zi-qian-ca-zheng-shu/"/>
      <url>/2021/08/20/zi-qian-ca-zheng-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="自签ca证书，及颁发证书"><a href="#自签ca证书，及颁发证书" class="headerlink" title="自签ca证书，及颁发证书"></a>自签ca证书，及颁发证书</h1><p>cd /etc/pki/CA</p><h2 id="服务端生成ca证书"><a href="#服务端生成ca证书" class="headerlink" title="服务端生成ca证书"></a>服务端生成ca证书</h2><p>自签名证书，依赖自己的私钥</p><ol><li><p>生成私钥文件</p><p><strong>(umask 077;openssl genrsa -out private/cakey.pem 4096)</strong></p></li><li><p>直接生成自签名的证书</p><p><strong>openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650</strong></p><blockquote><p><code>x509代表生成的是自签名的证书，不带x509代表是向ca生成的证书，不是自签名的</code> </p><p><strong>要借助私钥文件生成自签名的证书</strong></p></blockquote><p><img src="https://image.fyxemmmm.cn/blog/images/crt1.png" alt="ca证书生成"></p></li><li><p>查看证书信息</p><p><strong>openssl x509 -in cacert.pem -noout -text</strong></p><p><img src="https://image.fyxemmmm.cn/blog/images/crt2.png" alt="ca证书"></p></li></ol><h2 id="服务端生成证书数据库"><a href="#服务端生成证书数据库" class="headerlink" title="服务端生成证书数据库"></a>服务端生成证书数据库</h2><blockquote><p>这里由于我们是自己的宿主机作为ca的管理、吊销及维护，所以需要一个数据库</p></blockquote><ol><li><p><strong>touch /etc/pki/CA/index.txt</strong> 添加数据库文件</p></li><li><p><strong>touch /etc/pki/CA/serial</strong> 新证书要从几开始编号，这个是记录用的，16进制数</p></li><li><p><strong>echo 0F &gt; /etc/pki/CA/serial</strong> 下次颁发证书的时候 就是15这个编号了</p><p><img src="https://image.fyxemmmm.cn/blog/images/crt3.png" alt="颁发证书的编号"></p></li></ol><h2 id="客户端侧用户申请证书"><a href="#客户端侧用户申请证书" class="headerlink" title="客户端侧用户申请证书"></a>客户端侧用户申请证书</h2><blockquote><p>证书可能是给某个服务用，比如给https服务用，https可能有自己配置数据的文件夹</p></blockquote><ol><li><p>生成应用私钥</p><p><strong>(umask 066; openssl genrsa -out app.key 1024)</strong></p><blockquote><p>注: 你申请证书的时间不是由你说了算，是颁发机构说了算</p></blockquote></li><li><p>生成csr文件</p><p><strong>openssl req -new -key app.key -out app.csr</strong>  <code>之前ca通过x509参数生成的是自签名的证书 而且可以有有效期，这里是生成证书请求文件</code></p><p><img src="https://image.fyxemmmm.cn/blog/images/crt4.png" alt="三项必须一致，且commonName填写服务的名称"></p></li></ol><h2 id="服务端颁发证书"><a href="#服务端颁发证书" class="headerlink" title="服务端颁发证书"></a>服务端颁发证书</h2><p><strong>openssl ca -in /root/app.csr -out certs/app.crt -days 365 app.crt</strong>是别人用私钥生成的证书请求文件，会读取服务端宿主机的配置文件，所以没指定ca的私钥，也不需要的 <code>这就是用服务端的ca自签名</code></p><p><img src="https://image.fyxemmmm.cn/blog/images/crt5.png"></p><p>如果提交的东西都对，就可以y 进行签名了</p><p><img src="https://image.fyxemmmm.cn/blog/images/crt6.png"></p><p>证书申请完毕， 然后发给客户端使用 即可</p><hr><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>查看证书有效性</p><p><strong>openssl ca -status 0F</strong></p><p>查看证书的有效期</p><p><strong>openssl x509 -in app.crt -noout -dates</strong></p>]]></content>
      
      
      <categories>
          
          <category> 加密与安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 证书 </tag>
            
            <tag> ca </tag>
            
            <tag> 自签 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一张图带你搞懂http协议</title>
      <link href="/2021/08/19/yi-zhang-tu-dai-ni-li-jie-http/"/>
      <url>/2021/08/19/yi-zhang-tu-dai-ni-li-jie-http/</url>
      
        <content type="html"><![CDATA[<h2 id="一张图带你弄懂http协议"><a href="#一张图带你弄懂http协议" class="headerlink" title="一张图带你弄懂http协议"></a>一张图带你弄懂http协议</h2><p><img src="https://image.fyxemmmm.cn/blog/images/http.jpg"></p><blockquote><p>http优化点：<br><strong>初始拥塞窗口(慢启动)</strong> <strong>– 10个MMS，一开始一次性发10个，初始带宽就起来了</strong><br>rto <strong>一来一回，ping一下，这个rto比我们ping的值大一点，是定时器来采样的</strong><br>rto超时 就会重新经历慢启动<br>因为慢启动 tls<br>接收端 16kb收到了之后，openssl才能解压， 2个rtt， 体验很差 –&gt; 所以要使用fastopen<br>广播报文都只支持udp的</p></blockquote><h3 id="http缓存的工作原理"><a href="#http缓存的工作原理" class="headerlink" title="http缓存的工作原理"></a>http缓存的工作原理</h3><p>缓存都有指纹 叫etag或者时间</p><p><strong>然后get发送请求的时候带上etag，服务端判断etag有没有变化，没有变化，就把资源返回304（只有描述信息，节约了带宽）</strong></p><p>请求里带了指纹 if-none-match，包含了文件的长度和修改的时间，做了16进制的编码</p><p>服务器通过指纹比较没问题，又发(etag)回来了，304返回</p><p>No-cache 要和服务端协商一下，得到服务端304可以使用</p><p><img src="https://image.fyxemmmm.cn/blog/images/etag.png" alt="缓存工作原理"></p>]]></content>
      
      
      <categories>
          
          <category> 协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> http </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>硬核! 图解 golang [select case] 原理</title>
      <link href="/2021/08/18/golang-select-yuan-li/"/>
      <url>/2021/08/18/golang-select-yuan-li/</url>
      
        <content type="html"><![CDATA[<p>Go 的select语句是一种仅能用于channl发送和接收消息的专用语句，此语句运行期间是阻塞的；当select中没有case语句的时候，会阻塞当前的groutine。所以，有人也会说select是用来阻塞监听goroutine的。<br> 还有人说：select是Golang在语言层面提供的I/O多路复用的机制，其专门用来检测多个channel是否准备完毕：可读或可写。</p><p>以上说法都正确。</p><h2 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h2><p>我们来回顾一下是什么是<code>I/O多路复用</code>。</p><h3 id="普通多线程（或进程）I-O"><a href="#普通多线程（或进程）I-O" class="headerlink" title="普通多线程（或进程）I/O"></a>普通多线程（或进程）I/O</h3><p>每来一个进程，都会建立连接，然后阻塞，直到接收到数据返回响应。<br> 普通这种方式的缺点其实很明显：系统需要创建和维护额外的线程或进程。因为大多数时候，大部分阻塞的线程或进程是处于等待状态，只有少部分会接收并处理响应，而其余的都在等待。系统为此还需要多做很多额外的线程或者进程的管理工作。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select1.webp"></p><p>为了解决图中这些多余的线程或者进程，于是有了”I/O多路复用”</p><h3 id="I-O多路复用-1"><a href="#I-O多路复用-1" class="headerlink" title="I/O多路复用"></a>I/O多路复用</h3><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select2.webp"></p><p>每个线程或者进程都先到图中”装置“中注册，然后阻塞，然后只有一个线程在”运输“，当注册的线程或者进程准备好数据后，”装置“会根据注册的信息得到相应的数据。从始至终kernel只会使用图中这个黄黄的线程，无需再对额外的线程或者进程进行管理，提升了效率。</p><h2 id="select组成结构"><a href="#select组成结构" class="headerlink" title="select组成结构"></a>select组成结构</h2><p>select的实现经历了多个版本的修改，当前版本为：1.11<br> select这个语句底层实现实际上主要由两部分组成：<code>case语句</code>和<code>执行函数</code>。<br> 源码地址为：/go/src/runtime/select.go</p><p>每个case语句，单独抽象出以下结构体：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> scase <span class="token keyword">struct</span> <span class="token punctuation">{</span>    c           <span class="token operator">*</span>hchan         <span class="token comment">// chan</span>    elem        unsafe<span class="token punctuation">.</span>Pointer <span class="token comment">// 读或者写的缓冲区地址</span>    kind        <span class="token builtin">uint16</span>   <span class="token comment">//case语句的类型，是default、传值写数据(channel &lt;-) 还是  取值读数据(&lt;- channel)</span>    pc          <span class="token builtin">uintptr</span> <span class="token comment">// race pc (for race detector / msan)</span>    releasetime <span class="token builtin">int64</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结构体可以用下图表示：</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select3.webp"></p><p> 其中比较关键的是：<code>hchan</code>，它是channel的指针。<br> 在一个select中，所有的case语句会构成一个<code>scase</code>结构体的数组。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select4.webp"></p><p>然后执行select语句实际上就是调用<code>func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool)</code>函数。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select5.webp"></p><p><code>func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool)</code>函数参数：</p><ul><li>cas0 为上文提到的case语句抽象出的结构体<code>scase</code>数组的第一个元素地址</li><li>order0为一个两倍cas0数组长度的buffer，保存scase随机序列pollorder和scase中channel地址序列lockorder。</li><li>nncases表示<code>scase</code>数组的长度</li></ul><p><code>selectgo</code>返回所选scase的索引(该索引与其各自的select {recv，send，default}调用的序号位置相匹配)。此外，如果选择的scase是接收操作(recv)，则返回是否接收到值。</p><p>谁负责调用<code>func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool)</code>函数呢？</p><p>在<code>/reflect/value.go</code>中有个<code>func rselect([]runtimeSelect) (chosen int, recvOK bool)</code>函数，此函数的实现在<code>/runtime/select.go</code>文件中的<code>func reflect_rselect(cases []runtimeSelect) (int, bool)</code>函数中:</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">reflect_rselect</span><span class="token punctuation">(</span>cases <span class="token punctuation">[</span><span class="token punctuation">]</span>runtimeSelect<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>     <span class="token comment">//如果cases语句为空，则阻塞当前groutine</span>    <span class="token keyword">if</span> <span class="token function">len</span><span class="token punctuation">(</span>cases<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token function">block</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment">//实例化case的结构体</span>    sel <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span>scase<span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>cases<span class="token punctuation">)</span><span class="token punctuation">)</span>    order <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">uint16</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token operator">*</span><span class="token function">len</span><span class="token punctuation">(</span>cases<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token operator">:=</span> <span class="token keyword">range</span> cases <span class="token punctuation">{</span>        rc <span class="token operator">:=</span> <span class="token operator">&amp;</span>cases<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">switch</span> rc<span class="token punctuation">.</span>dir <span class="token punctuation">{</span>        <span class="token keyword">case</span> selectDefault<span class="token punctuation">:</span>            sel<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> scase<span class="token punctuation">{</span>kind<span class="token punctuation">:</span> caseDefault<span class="token punctuation">}</span>        <span class="token keyword">case</span> selectSend<span class="token punctuation">:</span>            sel<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> scase<span class="token punctuation">{</span>kind<span class="token punctuation">:</span> caseSend<span class="token punctuation">,</span> c<span class="token punctuation">:</span> rc<span class="token punctuation">.</span>ch<span class="token punctuation">,</span> elem<span class="token punctuation">:</span> rc<span class="token punctuation">.</span>val<span class="token punctuation">}</span>        <span class="token keyword">case</span> selectRecv<span class="token punctuation">:</span>            sel<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> scase<span class="token punctuation">{</span>kind<span class="token punctuation">:</span> caseRecv<span class="token punctuation">,</span> c<span class="token punctuation">:</span> rc<span class="token punctuation">.</span>ch<span class="token punctuation">,</span> elem<span class="token punctuation">:</span> rc<span class="token punctuation">.</span>val<span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> raceenabled <span class="token operator">||</span> msanenabled <span class="token punctuation">{</span>            <span class="token function">selectsetpc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sel<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token function">selectgo</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sel<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>order<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>cases<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>那谁调用的<code>func rselect([]runtimeSelect) (chosen int, recvOK bool)</code>呢？<br> 在<code>/refect/value.go</code>中，有一个<code>func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool)</code>的函数，其调用了<code>rselect</code>函数，并将最终Go中select语句的返回值的返回。</p><p>以上这三个函数的调用栈按顺序如下：</p><ul><li><code>func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool)</code></li><li><code>func rselect([]runtimeSelect) (chosen int, recvOK bool)</code></li><li><code>func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool)</code></li></ul><p>这仨函数中无论是返回值还是参数都大同小异，可以简单粗暴的认为：函数参数传入的是case语句，返回值返回被选中的case语句。<br> 那谁调用了<code>func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool)</code>呢？<br> 可以简单的认为是系统了。<br> 来个简单的图：</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select6.webp"></p><p>前两个函数<code>Select</code>和<code>rselect</code>都是做了简单的初始化参数，调用下一个函数的操作。select真正的核心功能，是在最后一个函数<code>func selectgo(cas0 *scase, order0 *uint16, ncases int) (int, bool)</code>中实现的。</p><h3 id="selectgo函数做了什么"><a href="#selectgo函数做了什么" class="headerlink" title="selectgo函数做了什么"></a>selectgo函数做了什么</h3><p>打乱传入的case结构体顺序</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select7.webp"></p><p>锁住其中的所有的channel</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select8.webp"></p><p>遍历所有的channel，查看其是否可读或者可写</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select9.webp"></p><p>如果其中的channel可读或者可写，则解锁所有channel，并返回对应的channel数据</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select10.webp"></p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select11.webp"></p><p>假如没有channel可读或者可写，但是有default语句，则同上:返回default语句对应的scase并解锁所有的channel。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select11.webp"></p><p>假如既没有channel可读或者可写，也没有default语句，则将当前运行的groutine阻塞，并加入到当前所有channel的等待队列中去。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select12.webp"></p><p>然后解锁所有channel，等待被唤醒。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select13.webp"></p><p>此时如果有个channel可读或者可写ready了，则唤醒，并再次加锁所有channel，</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select14.webp"></p><p>遍历所有channel找到那个对应的channel和G，唤醒G，并将没有成功的G从所有channel的等待队列中移除。</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select15.webp"></p><p>如果对应的scase值不为空，则返回需要的值，并解锁所有channel</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select16.webp"></p><p>如果对应的scase为空，则循环此过程。</p><h3 id="select和channel之间的关系"><a href="#select和channel之间的关系" class="headerlink" title="select和channel之间的关系"></a>select和channel之间的关系</h3><p>在想想select和channel做了什么事儿，我觉得和多路复用是一回事儿</p><p><img src="https://image.fyxemmmm.cn/blog/images/%E8%B5%84%E6%BA%90/select17.webp"></p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>kafka原理分析</title>
      <link href="/2021/08/17/kafka/"/>
      <url>/2021/08/17/kafka/</url>
      
        <content type="html"><![CDATA[<p><strong>Kafka痛点分析&amp;核心目标</strong></p><p>当Kafka支撑的实时作业数量很多，单机承载的Topic和Partition数量很大。这种场景下很容易出现的问题是：同一台机器上不同Partition间竞争PageCache资源，相互影响，导致整个Broker的处理延迟上升、吞吐下降。</p><p><img src="https://image.fyxemmmm.cn/blog/images/kafka.png" alt="Kafka处理读写流程的示意图"></p><p><strong>对于Produce请求</strong>：Server端的I/O线程统一将请求中的数据写入到操作系统的PageCache后立即返回，当消息条数到达一定阈值后，Kafka应用本身或操作系统内核会触发强制刷盘操作（如左侧流程图所示）。</p><p><strong>对于Consume请求</strong>：主要利用了操作系统的ZeroCopy机制，当Kafka Broker接收到读数据请求时，会向操作系统发送sendfile系统调用，操作系统接收后，首先试图从PageCache中获取数据（如中间流程图所示）；如果数据不存在，会触发缺页异常中断将数据从磁盘读入到临时缓冲区中（如右侧流程图所示），随后通过DMA操作直接将数据拷贝到网卡缓冲区中等待后续的TCP传输。</p><p>综上所述，Kafka对于单一读写请求均拥有很好的吞吐和延迟。处理写请求时，数据写入PageCache后立即返回，数据通过异步方式批量刷入磁盘，既保证了多数写请求都能有较低的延迟，同时批量顺序刷盘对磁盘更加友好。处理读请求时，实时消费的作业可以直接从PageCache读取到数据，请求延迟较小，同时ZeroCopy机制能够减少数据传输过程中用户态与内核态的切换，大幅提升了数据传输的效率。</p><p>但当同一个Broker上同时存在多个Consumer时，就可能会由于多个Consumer竞争PageCache资源导致它们同时产生延迟。下面我们以两个Consumer为例详细说明：</p><p><img src="https://image.fyxemmmm.cn/blog/images/kafka2.png"></p><p>如上图所示，Producer将数据发送到Broker，PageCache会缓存这部分数据。当所有Consumer的消费能力充足时，所有的数据都会从PageCache读取，全部Consumer实例的延迟都较低。此时如果其中一个Consumer出现消费延迟（图中的Consumer Process2），根据读请求处理流程可知，此时会触发磁盘读取，在从磁盘读取数据的同时会预读部分数据到PageCache中。当PageCache空间不足时，会按照LRU策略开始淘汰数据，此时延迟消费的Consumer读取到的数据会替换PageCache中实时的缓存数据。后续当实时消费请求到达时，由于PageCache中的数据已被替换掉，会产生预期外的磁盘读取。这样会导致两个后果：</p><ol><li><strong>消费能力充足的Consumer消费时会失去PageCache的性能红利。</strong></li><li><strong>多个Consumer相互影响，预期外的磁盘读增多，HDD负载升高。</strong></li></ol><p><strong>数据分析</strong></p><p>如果Kafka集群TP99流量在170MB/s，TP95流量在100MB/s，TP50流量为50-60MB/s；单机的PageCache平均分配为80GB，取TP99的流量作为参考，在此流量以及PageCache分配情况下，PageCache最大可缓存数据时间跨度为80*1024/170/60 = 8min，可见当前Kafka服务整体对延迟消费作业的容忍性极低。该情况下，一旦部分作业消费延迟，实时消费作业就可能会受到影响。</p><p><strong>痛点分析总结</strong></p><p>总结上述的原理分析以及数据统计，目前Kafka存在如下问题：</p><ol><li>实时消费与延迟消费的作业在PageCache层次产生竞争，导致实时消费产生非预期磁盘读。</li><li>传统HDD随着读并发升高性能急剧下降。</li><li>存在20%的延迟消费作业。</li></ol><p>按目前的PageCache空间分配以及集群流量分析，Kafka无法对实时消费作业提供稳定的服务质量保障，该痛点亟待解决。</p><p><strong>预期目标</strong></p><p>根据上述痛点分析，我们的预期目标为保证实时消费作业不会由于PageCache竞争而被延迟消费作业影响，保证Kafka对实时消费作业提供稳定的服务质量保障。</p><p><strong>解决方案</strong></p><p><strong>可以选择使用SSD</strong></p><p>根据上述原因分析可知，解决目前痛点可从以下两个方向来考虑：</p><ol><li>消除实时消费与延迟消费间的PageCache竞争，如：让延迟消费作业读取的数据不回写PageCache，或增大PageCache的分配量等。</li><li>在HDD与内存之间加入新的设备，该设备拥有比HDD更好的读写带宽与IOPS。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>tcp timewait 踩坑实战</title>
      <link href="/2021/08/17/tcp-timewait/"/>
      <url>/2021/08/17/tcp-timewait/</url>
      
        <content type="html"><![CDATA[<p><strong>你遇到过TIME_WAIT的问题吗？</strong></p><p>我相信很多都遇到过这个问题。一旦有用户在喊：网络变慢了。第一件事情就是，netstat -a | grep TIME_WAIT | wc -l 一下，哎呀妈呀，几千个TIME_WAIT。</p><p>然后，做的第一件事情就是：打开Google或者Bing，输入关键词：too many time wait。一定能找到解决方案，而排在最前面或者被很多人到处转载的解决方案一定是：</p><blockquote><p>打开 sysctl.conf 文件，修改以下几个参数：</p><p>net.ipv4.tcp_tw_recycle = 1</p><p>net.ipv4.tcp_tw_reuse = 1</p><p>net.ipv4.tcp_timestamps = 1</p></blockquote><p>你也会被告知，开启tw_recylce和tw_reuse一定需要timestamps的支持，而且这些配置一般不建议开启，但是对解决TIME_WAIT很多的问题，有很好的用处。</p><p>接下来，你就直接修改了这几个参数，reload一下，发现，咦，没几分钟，TIME_WAIT的数量真的降低了，也没发现哪个用户说有问题，然后就没有然后了。</p><p>做到这一步，相信50%或者更高比例的开发就已经止步了。问题好像解决了，但是，要彻底理解并解决这个问题，可能就没这么简单，或者说，还有很长的路要走！</p><p><strong>什么是TIME-WAIT和CLOSE-WAIT?</strong></p><p>所谓，要解决问题，就要先理解问题。随便改两行代码，发现bug“没有了”，也不是bug真的没有了，只是隐藏在更深的地方，你没有发现，或者以你的知识水平，你无法发现而已。</p><p>大家知道，由于socket是全双工的工作模式，一个socket的关闭，是需要四次握手来完成的。</p><ul><li>主动关闭连接的一方，调用close()；<strong>协议层发送FIN包</strong></li><li><strong>被动关闭的一方收到FIN包后，协议层回复ACK</strong>；然后<strong>被动关闭的一方，进入CLOSE_WAIT状态，</strong>主动关闭的一方等待对方关闭，则进入FIN_WAIT_2状态；此时，主动关闭的一方 等待 被动关闭一方的应用程序，调用close操作</li><li>被动关闭的一方在完成所有数据发送后，调用close()操作；此时，<strong>协议层发送FIN包给主动关闭的一方，等待对方的ACK，被动关闭的一方进入LAST_ACK状态</strong>；</li><li><strong>主动关闭的一方收到FIN包，协议层回复ACK</strong>；此时，<strong>主动关闭连接的一方，进入TIME_WAIT状态；而被动关闭的一方，进入CLOSED状态</strong></li><li>等待2MSL时间，主动关闭的一方，结束TIME_WAIT，进入CLOSED状态</li></ul><p>通过上面的一次socket关闭操作，你可以得出以下几点：</p><ol><li>主动关闭连接的一方 - 也就是主动调用socket的close操作的一方，最终会进入TIME_WAIT状态</li><li>被动关闭连接的一方，有一个中间状态，即CLOSE_WAIT，因为协议层在等待上层的应用程序，主动调用close操作后才主动关闭这条连接</li><li>TIME_WAIT会默认等待2MSL时间后，才最终进入CLOSED状态；</li><li>在一个连接没有进入CLOSED状态之前，这个连接是不能被重用的！</li></ol><p>所以，这里凭你的直觉，TIME_WAIT并不可怕（not really，后面讲），CLOSE_WAIT才可怕，因为CLOSE_WAIT很多，表示说要么是你的应用程序写的有问题，没有合适的关闭socket；要么是说，你的服务器CPU处理不过来（CPU太忙）或者你的应用程序一直睡眠到其它地方(锁，或者文件I/O等等)，你的应用程序获得不到合适的调度时间，造成你的程序没法真正的执行close操作。</p><p>这里又出现两个问题：</p><ol><li>上文提到的连接重用，那连接到底是个什么概念？</li><li>协议层为什么要设计一个TIME_WAIT状态？这个状态为什么默认等待2MSL时间才会进入CLOSED</li></ol><p>先解释清楚这两个问题，我们再来看，开头提到的几个网络配置究竟有什么用，以及TIME_WAIT的后遗症问题。</p><p><strong>Socket连接到底是个什么概念？</strong></p><p>大家经常提socket，那么，到底什么是一个socket？其实，socket就是一个 五元组，包括：</p><ol><li>源IP</li><li>源端口</li><li>目的IP</li><li>目的端口</li><li>类型：TCP or UDP</li></ol><p>这个五元组，即标识了一条可用的连接。注意，有很多人把一个socket定义成四元组，也就是 源IP:源端口 + 目的IP:目的端口，这个定义是不正确的。</p><p>例如，如果你的本地出口IP是180.172.35.150，那么你的浏览器在连接某一个Web服务器，例如百度的时候，这条socket连接的四元组可能就是：</p><blockquote><p>[180.172.35.150:45678, tcp, 180.97.33.108:80]</p></blockquote><p>源IP为你的出口IP地址 180.172.35.150，源端口为随机端口 45678，目的IP为百度的某一个负载均衡服务器IP 180.97.33.108，端口为HTTP标准的80端口。</p><p>如果这个时候，你再开一个浏览器，访问百度，将会产生一条新的连接：</p><blockquote><p>[180.172.35.150:43678, tcp, 180.97.33.108:80]</p></blockquote><p>这条新的连接的源端口为一个新的随机端口 43678。</p><p>如此来看，如果你的本机需要压测百度，那么，你最多可以创建多少个连接呢？</p><p><strong>第二个问题，TIME_WAIT有什么用？</strong></p><p>如果我们来做个类比的话，TIME_WAIT的出现，对应的是你的程序里的异常处理，它的出现，就是为了解决网络的丢包和网络不稳定所带来的其他问题：</p><p>第一，防止前一个连接【五元组，我们继续以 180.172.35.150:45678, tcp, 180.97.33.108:80 为例】上延迟的数据包或者丢失重传的数据包，被后面复用的连接【前一个连接关闭后，此时你再次访问百度，新的连接可能还是由180.172.35.150:45678, tcp, 180.97.33.108:80 这个五元组来表示，也就是源端口凑巧还是45678】错误的接收（异常：数据丢了，或者传输太慢了），参见下图：</p><ul><li>SEQ=3的数据包丢失，重传第一次，没有得到ACK确认</li><li>如果没有TIME_WAIT，或者TIME_WAIT时间非常端，那么关闭的连接【180.172.35.150:45678, tcp, 180.97.33.108:80 的状态变为了CLOSED，源端口可被再次利用】，马上被重用【对180.97.33.108:80新建的连接，复用了之前的随机端口45678】，并连续发送SEQ=1,2 的数据包</li><li>此时，前面的连接上的SEQ=3的数据包再次重传，同时，seq的序号刚好也是3（这个很重要，不然，SEQ的序号对不上，就会RST掉），此时，前面一个连接上的数据被后面的一个连接错误的接收</li></ul><p>第二，确保连接方能在时间范围内，关闭自己的连接。其实，也是因为丢包造成的，参见下图：</p><p><img src="https://image.fyxemmmm.cn/blog/images/img1.webp"></p><ul><li>主动关闭方关闭了连接，发送了FIN；</li><li>被动关闭方回复ACK同时也执行关闭动作，发送FIN包；此时，被动关闭的一方进入LAST_ACK状态</li><li>主动关闭的一方回去了ACK，主动关闭一方进入TIME_WAIT状态；</li><li>但是最后的ACK丢失，被动关闭的一方还继续停留在LAST_ACK状态</li><li>此时，如果没有TIME_WAIT的存在，或者说，停留在TIME_WAIT上的时间很短，则主动关闭的一方很快就进入了CLOSED状态，也即是说，如果此时新建一个连接，源随机端口如果被复用，在connect发送SYN包后，由于被动方仍认为这条连接【五元组】还在等待ACK，但是却收到了SYN，则被动方会回复RST</li><li>造成主动创建连接的一方，由于收到了RST，则连接无法成功</li></ul><p>所以，你看到了，TIME_WAIT的存在是很重要的，如果强制忽略TIME_WAIT，还是有很高的机率，造成数据粗乱，或者短暂性的连接失败。</p><p>那么，为什么说，TIME_WAIT状态会是持续2MSL（2倍的max segment lifetime）呢？这个时间可以通过修改内核参数调整吗？第一，这个2MSL，是RFC 793里定义的，参见RFC的截图标红的部分：</p><p><img src="https://image.fyxemmmm.cn/blog/images/img2.webp"></p><p>这个定义，更多的是一种保障（IP数据包里的TTL，即数据最多存活的跳数，真正反应的才是数据在网络上的存活时间），确保最后丢失了ACK，被动关闭的一方再次重发FIN并等待回复的ACK，一来一去两个来回。内核里，写死了这个MSL的时间为：30秒（有读者提醒，RFC里建议的MSL其实是2分钟，但是很多实现都是30秒），所以TIME_WAIT的即为1分钟：</p><p>所以，再次回想一下前面的问题，如果一条连接，即使在四次握手关闭了，由于TIME_WAIT的存在，这个连接，在1分钟之内，也无法再次被复用，那么，如果你用一台机器做压测的客户端，你一分钟能发送多少并发连接请求？如果这台是一个负载均衡服务器，一台负载均衡服务器，一分钟可以有多少个连接同时访问后端的服务器呢？</p><p><strong>TIME_WAIT很多，可怕吗？</strong></p><p>如果你通过 ss -tan state time-wait | wc -l 发现，系统中有很多TIME_WAIT，很多人都会紧张。多少算多呢？几百几千？如果是这个量级，其实真的没必要紧张。第一，这个量级，因为TIME_WAIT所占用的内存很少很少；因为记录和寻找可用的local port所消耗的CPU也基本可以忽略。</p><p><strong>会占用内存吗？当然</strong>！任何你可以看到的数据，内核里都需要有相关的数据结构来保存这个数据啊。一条Socket处于TIME_WAIT状态，它也是一条“存在”的socket，内核里也需要有保持它的数据：</p><ol><li><p>内核里有保存所有连接的一个hash table，这个hash table里面既包含TIME_WAIT状态的连接，也包含其他状态的连接。主要用于有新的数据到来的时候，从这个hash table里快速找到这条连接。不同的内核对这个hash table的大小设置不同，你可以通过dmesg命令去找到你的内核设置的大小：</p></li><li><p>还有一个hash table用来保存所有的bound ports，主要用于可以快速的找到一个可用的端口或者随机端口：</p></li></ol><p>由于内核需要保存这些数据，必然，会占用一定的内存。</p><p><strong>会消耗CPU吗？</strong>当然！每次找到一个随机端口，还是需要遍历一遍bound ports的吧，这必然需要一些CPU时间。</p><p>TIME_WAIT很多，既占内存又消耗CPU，这也是为什么很多人，看到TIME_WAIT很多，就蠢蠢欲动的想去干掉他们。其实，如果你再进一步去研究，1万条TIME_WAIT的连接，也就多消耗1M左右的内存，对现代的很多服务器，已经不算什么了。至于CPU，能减少它当然更好，但是不至于因为1万多个hash item就担忧。</p><p>如果，你真的想去调优，还是需要搞清楚别人的调优建议，以及调优参数背后的意义！</p><p><strong>TIME_WAIT调优，你必须理解的几个调优参数</strong></p><p>在具体的图例之前，我们还是先解析一下相关的几个参数存在的意义。</p><ol><li><p><strong>net.ipv4.tcp_timestamps</strong></p><p>RFC 1323 在 TCP Reliability一节里，引入了timestamp的TCP option，两个4字节的时间戳字段，其中第一个4字节字段用来保存发送该数据包的时间，第二个4字节字段用来保存最近一次接收对方发送到数据的时间。有了这两个时间字段，也就有了后续优化的余地。</p><p>tcp_tw_reuse 和 tcp_tw_recycle就依赖这些时间字段。</p></li><li><p><strong>net.ipv4.tcp_tw_reuse</strong></p><p>字面意思，reuse TIME_WAIT状态的连接。</p><p>时刻记住一条socket连接，就是那个五元组，出现TIME_WAIT状态的连接，一定出现在主动关闭连接的一方。所以，当主动关闭连接的一方，再次向对方发起连接请求的时候（例如，客户端关闭连接，客户端再次连接服务端，此时可以复用了；负载均衡服务器，主动关闭后端的连接，当有新的HTTP请求，负载均衡服务器再次连接后端服务器，此时也可以复用），可以复用TIME_WAIT状态的连接。</p><p>通过字面解释，以及例子说明，你看到了，tcp_tw_reuse应用的场景：某一方，需要不断的通过“短连接”连接其他服务器，总是自己先关闭连接(TIME_WAIT在自己这方)，关闭后又不断的重新连接对方。</p><p>那么，当连接被复用了之后，延迟或者重发的数据包到达，新的连接怎么判断，到达的数据是属于复用后的连接，还是复用前的连接呢？那就需要依赖前面提到的两个时间字段了。复用连接后，这条连接的时间被更新为当前的时间，当延迟的数据达到，延迟数据的时间是小于新连接的时间，所以，内核可以通过时间判断出，延迟的数据可以安全的丢弃掉了。</p><p>这个配置，依赖于连接双方，同时对timestamps的支持。同时，这个配置，仅仅影响outbound连接，即做为客户端的角色，连接服务端[connect(dest_ip, dest_port)]时复用TIME_WAIT的socket。</p></li><li><p><strong>net.ipv4.tcp_tw_recycle</strong></p><p>字面意思，销毁掉 TIME_WAIT。</p><p>当开启了这个配置后，内核会快速的回收处于TIME_WAIT状态的socket连接。多快？不再是2MSL，而是一个RTO（retransmission timeout，数据包重传的timeout时间）的时间，这个时间根据RTT动态计算出来，但是远小于2MSL。</p><p>有了这个配置，还是需要保障 丢失重传或者延迟的数据包，不会被新的连接(注意，这里不再是复用了，而是之前处于TIME_WAIT状态的连接已经被destroy掉了，新的连接，刚好是和某一个被destroy掉的连接使用了相同的五元组而已)所错误的接收。在启用该配置，当一个socket连接进入TIME_WAIT状态后，内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据，当然也包括从该对方IP所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。</p><p>这个配置，依赖于连接双方对timestamps的支持。同时，这个配置，主要影响到了inbound的连接（对outbound的连接也有影响，但是不是复用），即做为服务端角色，客户端连进来，服务端主动关闭了连接，TIME_WAIT状态的socket处于服务端，服务端快速的回收该状态的连接。</p></li></ol><p>由此，如果客户端处于NAT的网络(多个客户端，同一个IP出口的网络环境)，如果配置了tw_recycle，就可能在一个RTO的时间内，只能有一个客户端和自己连接成功(不同的客户端发包的时间不一致，造成服务端直接把数据包丢弃掉)。</p><p>我尽量尝试用文字解释清楚，但是，来点案例和图示，应该有助于我们彻底理解。</p><p>我们来看这样一个网络情况：</p><ol><li>客户端IP地址为：180.172.35.150，我们可以认为是浏览器</li><li>负载均衡有两个IP，外网IP地址为 115.29.253.156，内网地址为10.162.74.10；外网地址监听80端口</li><li>负载均衡背后有两台Web服务器，一台IP地址为 10.162.74.43，监听80端口；另一台为 10.162.74.44，监听 80 端口</li><li>Web服务器会连接数据服务器，IP地址为 10.162.74.45，监听 3306 端口</li></ol><p>这种简单的架构下，我们来看看，在不同的情况下，我们今天谈论的tw_reuse/tw_recycle对网络连接的影响。</p><p>先做个假定：</p><ol><li>客户端通过HTTP/1.1连接负载均衡，也就是说，HTTP协议投Connection为keep-alive，所以我们假定，客户端 对 负载均衡服务器 的socket连接，客户端会断开连接，所以，TIME_WAIT出现在客户端</li><li>Web服务器和MySQL服务器的连接，我们假定，Web服务器上的程序在连接结束的时候，调用close操作关闭socket资源连接，所以，TIME_WAIT出现在 Web 服务器端。</li></ol><p>那么，在这种假定下：</p><ol><li>Web服务器上，肯定可以配置开启的配置：tcp_tw_reuse；如果Web服务器有很多连向DB服务器的连接，可以保证socket连接的复用。</li><li>那么，负载均衡服务器和Web服务器，谁先关闭连接，则决定了我们怎么配置tcp_tw_reuse/tcp_tw_recycle了</li></ol><p><strong>场景一：负载均衡服务器首先关闭连接</strong> </p><p>在这种情况下，因为负载均衡服务器对Web服务器的连接，TIME_WAIT大都出现在负载均衡服务器上。</p><p>在负载均衡服务器上的配置：</p><ul><li>net.ipv4.tcp_tw_reuse = 1 //尽量复用连接</li><li>net.ipv4.tcp_tw_recycle = 0 //不能保证客户端不在NAT的网络啊</li></ul><p>在Web服务器上的配置为：</p><ul><li>net.ipv4.tcp_tw_reuse = 1 //这个配置主要影响的是Web服务器到DB服务器的连接复用</li><li>net.ipv4.tcp_tw_recycle： 设置成1和0都没有任何意义。想一想，在负载均衡和它的连接中，它是服务端，但是TIME_WAIT出现在负载均衡服务器上；它和DB的连接，它是客户端，recycle对它并没有什么影响，关键是reuse</li></ul><p><strong>场景二：Web服务器首先关闭来自负载均衡服务器的连接</strong></p><p>在这种情况下，Web服务器变成TIME_WAIT的重灾区。负载均衡对Web服务器的连接，由Web服务器首先关闭连接，TIME_WAIT出现在Web服务器上；Web服务器对DB服务器的连接，由Web服务器关闭连接，TIME_WAIT也出现在它身上，此时，负载均衡服务器上的配置：</p><ul><li>net.ipv4.tcp_tw_reuse：0 或者 1 都行，都没有实际意义</li><li>net.ipv4.tcp_tw_recycle=0 //一定是关闭recycle</li></ul><p>在Web服务器上的配置：</p><ul><li>net.ipv4.tcp_tw_reuse = 1 //这个配置主要影响的是Web服务器到DB服务器的连接复用</li><li>net.ipv4.tcp_tw_recycle=1 //由于在负载均衡和Web服务器之间并没有NAT的网络，可以考虑开启recycle，加速由于负载均衡和Web服务器之间的连接造成的大量TIME_WAIT</li></ul>]]></content>
      
      
      <categories>
          
          <category> 协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
            <tag> tcp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes高可用集群搭建</title>
      <link href="/2021/08/16/k8s-install/"/>
      <url>/2021/08/16/k8s-install/</url>
      
        <content type="html"><![CDATA[<h1 id="k8s-高可用集群搭建"><a href="#k8s-高可用集群搭建" class="headerlink" title="k8s 高可用集群搭建"></a>k8s 高可用集群搭建</h1><p><code>docker的安装自行搞定即可, 尽量不要用太高版本到version.19即可</code></p><p><strong>本文基于centos的操作系统，kubeadm来作为搭建方式</strong></p><ol><li><p>新建yum源</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpghttps://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOFsudo yum makecachesudo yum -y install kubelet-1.20.2  kubeadm-1.20.2  kubectl-1.20.2sudo systemctl enable kubelet<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>使用systemd作为docker的cgroup driver</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">sudo vi  /etc/docker/daemon.json   （没有则创建）加入{  "exec-opts": ["native.cgroupdriver=systemd"]}systemctl daemon-reload  &amp;&amp; systemctl restart docker<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>切换到root用户执行 <strong>关键步骤</strong></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"># （如果是重置机器，需要执行）kubeadm resetrm /etc/cni/net.d -friptables -F yum -y remove kubelet-1.18.6  kubeadm-1.18.6  kubectl-1.18.6# （重置end）yum -y install kubelet-1.20.2  kubeadm-1.20.2  kubectl-1.20.2echo 1 &gt; /proc/sys/net/ipv4/ip_forwardmodprobe br_netfilterecho 1 &gt; /proc/sys/net/bridge/bridge-nf-call-iptablessystemctl daemon-reload  # 可能会报错 可以不执行这个systemctl enable kubelet<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>master节点执行以下命令</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#主机执行：kubeadm init --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers  --kubernetes-version=1.20.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>得到token之后给worker依次执行， 加入到集群当中去， <code>初步就完成了集群的搭建</code> <strong>还差一个网络插件</strong></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#得到token后，给另外worker去执行kubeadm join 192.168.0.191:6443 --token zx5rj1.19yqkv7q2uehatit \--discovery-token-ca-cert-hash sha256:b5a066c56e73896dc14530d5464eadd45732de6bd3806e878c80ed589e4ea502<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>给节点做一些完善工作</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#然后退出到普通用户, 用kubectl命令执行#去除主节点污点kubectl taint nodes --all node-role.kubernetes.io/master-   # (后面一个 – 是需要的)给工作节点打标签kubectl label node huawei-worker  node-role.kubernetes.io/node=node<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>我们需要让外网也可以访问， <strong>也就是通过kubectl客户端工具能连接主机的外部ip地址，需要做此工作</strong></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">#让外网可以访问#先删除 apiserver的证书和key#主节点上cd /etc/kubernetes/pki &amp;&amp; rm -f apiserver.key &amp;&amp; rm -f  apiserver.crtsudo kubeadm init phase certs apiserver   --apiserver-cert-extra-sans 121.36.226.197kubeadm alpha certs renew apiserver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>安装网络插件， <strong>这里我们选择flannel</strong></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">https://github.com/flannel-io/flannelFor Kubernetes v1.17+ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml# apply里面的镜像要替换下，可以用katacoda<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="大功告成啦-可以愉快的玩耍了！"><a href="#大功告成啦-可以愉快的玩耍了！" class="headerlink" title="大功告成啦~   可以愉快的玩耍了！"></a>大功告成啦~   可以愉快的玩耍了！</h3>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>golang context 实现原理</title>
      <link href="/2021/08/14/context-shi-xian-yuan-li/"/>
      <url>/2021/08/14/context-shi-xian-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="0-引言"><a href="#0-引言" class="headerlink" title="0 引言"></a>0 引言</h2><p>本文主要谈谈以下几个方面的内容：</p><ol><li>context的使用。</li><li>context实现原理，哪些是需要注意的地方</li><li>context的最佳实践。</li></ol><p><code>context</code>是Go中广泛使用的程序包，由Google官方开发，在1.7版本引入。它用来简化在多个go routine传递上下文数据、(手动/超时)中止routine树等操作，比如，官方http包使用context传递请求的上下文数据，gRpc使用context来终止某个请求产生的routine树。由于它使用简单，现在基本成了编写go基础库的通用规范。笔者在使用context上有一些经验，遂分享下。</p><p>本文主要谈谈以下几个方面的内容：</p><ol><li>context的使用。</li><li>context实现原理，哪些是需要注意的地方。</li><li>在实践中遇到的问题，分析问题产生的原因。</li></ol><h2 id="1-使用"><a href="#1-使用" class="headerlink" title="1 使用"></a>1 使用</h2><h3 id="核心接口Context"><a href="#核心接口Context" class="headerlink" title="核心接口Context"></a>核心接口Context</h3><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> Context <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token comment">// Deadline returns the time when work done on behalf of this context</span>    <span class="token comment">// should be canceled. Deadline returns ok==false when no deadline is</span>    <span class="token comment">// set.</span>    <span class="token function">Deadline</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>deadline time<span class="token punctuation">.</span>Time<span class="token punctuation">,</span> ok <span class="token builtin">bool</span><span class="token punctuation">)</span>    <span class="token comment">// Done returns a channel that's closed when work done on behalf of this</span>    <span class="token comment">// context should be canceled.</span>    <span class="token function">Done</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;-</span><span class="token keyword">chan</span> <span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment">// Err returns a non-nil error value after Done is closed.</span>    <span class="token function">Err</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span>    <span class="token comment">// Value returns the value associated with this context for key.</span>    <span class="token function">Value</span><span class="token punctuation">(</span>key <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>简单介绍一下其中的方法：<br>- <code>Done</code>会返回一个channel，当该context被取消的时候，该channel会被关闭，同时对应的使用该context的routine也应该结束并返回。<br>- <code>Context</code>中的方法是协程安全的，这也就代表了在父routine中创建的context，可以传递给任意数量的routine并让他们同时访问。<br>- <code>Deadline</code>会返回一个超时时间，routine获得了超时时间后，可以对某些io操作设定超时时间。<br>- <code>Value</code>可以让routine共享一些数据，当然获得数据是协程安全的。</p><p>在请求处理的过程中，会调用各层的函数，每层的函数会创建自己的routine，是一个routine树。所以，context也应该反映并实现成一棵树。</p><p>要创建context树，第一步是要有一个根结点。<code>context.Background</code>函数的返回值是一个空的context，经常作为树的根结点，它一般由接收请求的第一个routine创建，不能被取消、没有值、也没有过期时间。</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">Background</span><span class="token punctuation">(</span><span class="token punctuation">)</span> Context<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>之后该怎么创建其它的子孙节点呢？context包为我们提供了以下函数：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">WithCancel</span><span class="token punctuation">(</span>parent Context<span class="token punctuation">)</span> <span class="token punctuation">(</span>ctx Context<span class="token punctuation">,</span> cancel CancelFunc<span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">WithDeadline</span><span class="token punctuation">(</span>parent Context<span class="token punctuation">,</span> deadline time<span class="token punctuation">.</span>Time<span class="token punctuation">)</span> <span class="token punctuation">(</span>Context<span class="token punctuation">,</span> CancelFunc<span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">WithTimeout</span><span class="token punctuation">(</span>parent Context<span class="token punctuation">,</span> timeout time<span class="token punctuation">.</span>Duration<span class="token punctuation">)</span> <span class="token punctuation">(</span>Context<span class="token punctuation">,</span> CancelFunc<span class="token punctuation">)</span><span class="token keyword">func</span> <span class="token function">WithValue</span><span class="token punctuation">(</span>parent Context<span class="token punctuation">,</span> key <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> val <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> Context<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这四个函数的第一个参数都是父context，返回一个Context类型的值，这样就层层创建出不同的节点。子节点是从复制父节点得到的，并且根据接收的函数参数保存子节点的一些状态值，然后就可以将它传递给下层的routine了。</p><p><code>WithCancel</code>函数，返回一个额外的CancelFunc函数类型变量，该函数类型的定义为：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> CancelFunc <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>调用CancelFunc对象将撤销对应的Context对象，这样父结点的所在的环境中，获得了撤销子节点context的权利，当触发某些条件时，可以调用CancelFunc对象来终止子结点树的所有routine。在子节点的routine中，需要用类似下面的代码来判断何时退出routine：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">select</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> <span class="token operator">&lt;-</span>cxt<span class="token punctuation">.</span><span class="token function">Done</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">// do some cleaning and return</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>根据cxt.Done()判断是否结束。当顶层的Request请求处理结束，或者外部取消了这次请求，就可以cancel掉顶层context，从而使整个请求的routine树得以退出。</p><p><code>WithDeadline</code>和<code>WithTimeout</code>比<code>WithCancel</code>多了一个时间参数，它指示context存活的最长时间。如果超过了过期时间，会自动撤销它的子context。所以context的生命期是由父context的routine和<code>deadline</code>共同决定的。</p><p><code>WithValue</code>返回parent的一个副本，该副本保存了传入的key/value，而调用Context接口的Value(key)方法就可以得到val。注意在同一个context中设置key/value，若key相同，值会被覆盖。</p><h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2 原理"></a>2 原理</h2><h2 id="2-1-上下文数据的存储与查询"><a href="#2-1-上下文数据的存储与查询" class="headerlink" title="2.1 上下文数据的存储与查询"></a>2.1 上下文数据的存储与查询</h2><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> valueCtx <span class="token keyword">struct</span> <span class="token punctuation">{</span>    Context    key<span class="token punctuation">,</span> val <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">WithValue</span><span class="token punctuation">(</span>parent Context<span class="token punctuation">,</span> key<span class="token punctuation">,</span> val <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> Context <span class="token punctuation">{</span>    <span class="token keyword">if</span> key <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token function">panic</span><span class="token punctuation">(</span><span class="token string">"nil key"</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>valueCtx<span class="token punctuation">{</span>parent<span class="token punctuation">,</span> key<span class="token punctuation">,</span> val<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>c <span class="token operator">*</span>valueCtx<span class="token punctuation">)</span> <span class="token function">Value</span><span class="token punctuation">(</span>key <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> c<span class="token punctuation">.</span>key <span class="token operator">==</span> key <span class="token punctuation">{</span>        <span class="token keyword">return</span> c<span class="token punctuation">.</span>val    <span class="token punctuation">}</span>    <span class="token keyword">return</span> c<span class="token punctuation">.</span>Context<span class="token punctuation">.</span><span class="token function">Value</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>context上下文数据的存储就像一个树，每个结点只存储一个key/value对。<code>WithValue()</code>保存一个key/value对，它将父context嵌入到新的子context，并在节点中保存了key/value数据。<code>Value()</code>查询key对应的value数据，会从当前context中查询，如果查不到，会递归查询父context中的数据。</p><p>值得注意的是，<strong>context中的上下文数据并不是全局的，它只查询本节点及父节点们的数据，不能查询兄弟节点的数据。</strong></p><h2 id="2-2-手动cancel和超时cancel"><a href="#2-2-手动cancel和超时cancel" class="headerlink" title="2.2 手动cancel和超时cancel"></a>2.2 手动cancel和超时cancel</h2><p><code>cancelCtx</code>中嵌入了父Context，实现了canceler接口：</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> cancelCtx <span class="token keyword">struct</span> <span class="token punctuation">{</span>    Context      <span class="token comment">// 保存parent Context</span>    done <span class="token keyword">chan</span> <span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    mu       sync<span class="token punctuation">.</span>Mutex    children <span class="token keyword">map</span><span class="token punctuation">[</span>canceler<span class="token punctuation">]</span><span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    err      <span class="token builtin">error</span><span class="token punctuation">}</span><span class="token comment">// A canceler is a context type that can be canceled directly. The</span><span class="token comment">// implementations are *cancelCtx and *timerCtx.</span><span class="token keyword">type</span> canceler <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token function">cancel</span><span class="token punctuation">(</span>removeFromParent <span class="token builtin">bool</span><span class="token punctuation">,</span> err <span class="token builtin">error</span><span class="token punctuation">)</span>    <span class="token function">Done</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;-</span><span class="token keyword">chan</span> <span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>cancelCtx</code>结构体中<code>children</code>保存它的所有<code>子canceler</code>， 当外部触发cancel时，会调用<code>children</code>中的所有<code>cancel()</code>来终止所有的<code>cancelCtx</code>。<code>done</code>用来标识是否已被cancel。当外部触发cancel、或者父Context的channel关闭时，此done也会关闭。</p><pre class="line-numbers language-go" data-language="go"><code class="language-go"><span class="token keyword">type</span> timerCtx <span class="token keyword">struct</span> <span class="token punctuation">{</span>    cancelCtx     <span class="token comment">//cancelCtx.Done()关闭的时机：1）用户调用cancel 2）deadline到了 3）父Context的done关闭了</span>    timer    <span class="token operator">*</span>time<span class="token punctuation">.</span>Timer    deadline time<span class="token punctuation">.</span>Time<span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">WithDeadline</span><span class="token punctuation">(</span>parent Context<span class="token punctuation">,</span> deadline time<span class="token punctuation">.</span>Time<span class="token punctuation">)</span> <span class="token punctuation">(</span>Context<span class="token punctuation">,</span> CancelFunc<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token operator">...</span>    c <span class="token operator">:=</span> <span class="token operator">&amp;</span>timerCtx<span class="token punctuation">{</span>        cancelCtx<span class="token punctuation">:</span> <span class="token function">newCancelCtx</span><span class="token punctuation">(</span>parent<span class="token punctuation">)</span><span class="token punctuation">,</span>        deadline<span class="token punctuation">:</span>  deadline<span class="token punctuation">,</span>    <span class="token punctuation">}</span>    <span class="token function">propagateCancel</span><span class="token punctuation">(</span>parent<span class="token punctuation">,</span> c<span class="token punctuation">)</span>    d <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>deadline<span class="token punctuation">)</span>    <span class="token keyword">if</span> d <span class="token operator">&lt;=</span> <span class="token number">0</span> <span class="token punctuation">{</span>        c<span class="token punctuation">.</span><span class="token function">cancel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> DeadlineExceeded<span class="token punctuation">)</span> <span class="token comment">// deadline has already passed</span>        <span class="token keyword">return</span> c<span class="token punctuation">,</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> c<span class="token punctuation">.</span><span class="token function">cancel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> Canceled<span class="token punctuation">)</span> <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    c<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> c<span class="token punctuation">.</span>mu<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> c<span class="token punctuation">.</span>err <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        c<span class="token punctuation">.</span>timer <span class="token operator">=</span> time<span class="token punctuation">.</span><span class="token function">AfterFunc</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            c<span class="token punctuation">.</span><span class="token function">cancel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> DeadlineExceeded<span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> c<span class="token punctuation">,</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> c<span class="token punctuation">.</span><span class="token function">cancel</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> Canceled<span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>timerCtx</code>结构体中<code>deadline</code>保存了超时的时间，当超过这个时间，会触发<code>cancel</code>。</p><p><img src="https://image.fyxemmmm.cn/blog/images/ctx1.jpg"></p><p>可以看出，<strong>cancelCtx也是一棵树，当触发cancel时，会cancel本结点和其子树的所有cancelCtx</strong>。</p><h2 id="3-最佳实践"><a href="#3-最佳实践" class="headerlink" title="3 最佳实践"></a>3 最佳实践</h2><p>由于go大量的官方库、第三方库使用了context，所以调用<code>接收context的函数</code>时要小心，要清楚context在什么时候cancel，什么行为会触发cancel。笔者在程序经常使用gRpc传出来的context，产生了一些非预期的结果，之后花时间总结了gRpc、内部基础库中context的生命期及行为，以避免出现同样的问题。</p>]]></content>
      
      
      <categories>
          
          <category> golang </category>
          
      </categories>
      
      
        <tags>
            
            <tag> golang </tag>
            
            <tag> context </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
